<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Tech on Yuantops&#39; Blog</title><link>https://blog.yuantops.com/categories/tech/</link><description>Recent content in Tech on Yuantops&#39; Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><managingEditor>yuan.tops@gmail.com (yuantops)</managingEditor><webMaster>yuan.tops@gmail.com (yuantops)</webMaster><copyright>All rights reserved.</copyright><lastBuildDate>Wed, 01 Sep 2021 00:00:00 +0800</lastBuildDate><atom:link href="https://blog.yuantops.com/categories/tech/index.xml" rel="self" type="application/rss+xml"/><item><title>一次顿悟</title><link>https://blog.yuantops.com/tech/some_eureka_moment/</link><pubDate>Wed, 01 Sep 2021 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/some_eureka_moment/</guid><description>最近用 Emacs ox-hugo 写了几篇文章，体验比较糟，表现为总是无理由卡顿，特别是在 org 页面按下 `Ctrl-C, Ctrl-E`导出markdown时直接卡死，好几次只能强行杀掉Emacs 进程。
总所周知，Emacs 是神的编辑器，肯定不会出问题；我不爽，必定是我不会用了。于是，我鼓足勇气，想看看是哪里出了问题。
经过辛勤搜索，各种修改配置，纹丝不动。焦躁之余，不禁回忆起往事……
原本我是坚定vim党，自得其乐。
后来，受网络meme影响，终于买了一本讲Emacs的电子书，开始像八爪章鱼一样学按键，键位那么多，组合那么多。。。草草翻完一遍，只剩下 &amp;ldquo;这也行！&amp;rdquo; 的感叹号。试了 Dired, Magit, 自觉太复杂，难以记忆。放弃之。
又过了一段时间，心又痒痒了……这次吃了 org 的安利，GTD 好厉害！！大概实践了两个星期，只记得按 Tab 键可以切换标题等级。
下一次入坑，是受到 ox-hugo 的蛊惑: 确实如行云流水，非常满意。
想到这里，我顿悟了，我只是为了 org-mode 和 ox-hugo 啊 ！ Emacs 再怎么厉害，别人用得再怎么出神入化，用它写代码(特别写Java!!)、看小说、玩游戏、看视频…… 和我有什么关系呢? 弱水三千，只需取一瓢。
于是，爽爽快快删掉攒了多年的配置:
rm -fr .emacs.d 热情投向 spacemacs 怀抱:
git clone -b develop https://github.com/syl20bnr/spacemacs .emacs.d 启动emacs。因为是spacemacs第一次加载配置文件，会有一些询问交互。一路选择最小化配置。
最后修改 .spacemacs, 加上 ox-hugo 支持:
1 2 3 (setq-default dotspacemacs-configuration-layers &amp;#39;((org :variables org-enable-hugo-support t))) 重新加载配置，完完全全就好了！</description></item><item><title>H2 Database hack —— 批量插入的猥琐实现</title><link>https://blog.yuantops.com/tech/h2_database_hack_batch_insert/</link><pubDate>Fri, 27 Aug 2021 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/h2_database_hack_batch_insert/</guid><description>H2 数据库是一款优秀的内存数据库，它具备几个特点：体积小，文档全，功能完善，而且是Java写的。
最近用到它这些优良特性，做内存计算。以内存模式启动了一个H2实例。接下来，要把外部数据导入H2数据库。这就面临一个问题：数据量大（几万+）的情况下，如何保证插入速度？
常规方案 随便一种JDBC 持久层工具, 例如 JdbcTemplate, MyBatis,都封装了批量接口。怀着封装越少、效率越高的朴素信念，用H2原生JDBC Connection.insert() 方法，循环插入。2.7 万条数据，耗时约 3s。
另外，h2 database 官方有一种做法：把数据先导到 csv 文件，然后加载csv。虽没有实际验证这种方案，但纸上谈兵分析，即使数据加载变快，但增加了两次I/O。效果估计不会特别优秀。
快速方案 同事脑洞大开：内存数据库插入语句，先是SQL解析，再把Java对象写进内存。既然都是Java 对象，能不能跳过SQL这一遭，直接写内存?
不经过JDBC，不经过SQL，这种思路也是不按常规出牌了。但原理非常说得通，而且肯定更快。
经过一步步断点调试，找到了关键类: org.h2.table.Table 。insert() 语句走到最后，是往table 里添加行(org.h2.result.Row)。换言之，只要拿到 table，又按格式构造行，就可以了。
获取Table 按作者原意，应该是不希望使用者直接操作 Table 对象的。但是架不住我们猥琐啊，借助反射机制，什么都拿得到。 下面，是一步步抠出 Table 对象的实现。
String sql = &amp;quot;select * from &amp;quot; + tableName; try (JdbcPreparedStatement ps = (JdbcPreparedStatement) connection.prepareStatement(sql)) { CommandContainer commandContainer = (CommandContainer) getFieldByForce(ps, JdbcPreparedStatement.class, &amp;quot;command&amp;quot;); Session session = (Session) getFieldByForce(ps, JdbcPreparedStatement.class, &amp;quot;session&amp;quot;); Select command = (Select) getFieldByForce(commandContainer, CommandContainer.</description></item><item><title>TCP TIME_WAIT 连接太多</title><link>https://blog.yuantops.com/tech/linux_tcp_time_wait_tuning/</link><pubDate>Tue, 24 Aug 2021 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/linux_tcp_time_wait_tuning/</guid><description>压测一个服务，性能卡住了上不去。错误信息提示是没有可分配端口。搜索发现别人也遇到过类似问题(linux 大量的TIME_WAIT解决办法)。
把解决配置摘录如下：
配置 tcp 连接参数 vim /etc/sysctl.conf 编辑文件，加入以下内容：
net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_fin_timeout = 30 另外，也要关注系统本身对资源限制: 配置 /etc/security/limits.conf，把值加大:
* soft nofile 65535 * hard nofile 65535 * soft nproc 65535 * hard nproc 65535 net.ipv4.tcp_fin_timeout 做了啥? Stackoverflow 网友如是说:
Your link is urban myth. The actual function of net.ipv4.tcp_fin_timeout is as follows: This specifies how many seconds to wait for a final FIN packet before the socket is forcibly closed.</description></item><item><title>nginx 反向代理不开启http1.1时的行为探究</title><link>https://blog.yuantops.com/tech/nginx_proxy_pass_without_enable_http1/</link><pubDate>Tue, 24 Aug 2021 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/nginx_proxy_pass_without_enable_http1/</guid><description>最近给一个tomcat服务加上nginx代理，陆续遇到一些问题（坑）。
第一个坑，一个接口直接访问正常，经nginx代理后报104错误(104: Connection reset by peer)。奇葩之处在于，只有特定的接口出现这种错。
先说解决方案：配置反向代理长链接 很容易搜到104错误的解决方案.在nginx配置中，加上下面两句:
proxy_http_version 1.1; proxy_set_header Connection &amp;quot;&amp;quot;; 加上之后，执行命令 nginx -s reload 生效。
翻看nginx官方文档，这么说:
For HTTP, the proxy_http_version directive should be set to “1.1” and the “Connection” header field should be cleared: upstream http_backend { server 127.0.0.1:8080; keepalive 16; } server { ... location /http/ { proxy_pass http://http_backend; proxy_http_version 1.1; proxy_set_header Connection &amp;quot;&amp;quot;; ... } } 到这里，问题已经解决。我们再进一步，看看配置前后的区别。
tcpdump 抓包 在修改前后，各自抓包。
tcpdump -iensxxx -vvvs0 -l -A &amp;lsquo;tcp port 80 or tcp port 8082&amp;rsquo; -w tcpdump.</description></item><item><title>分布式追踪系统之我见</title><link>https://blog.yuantops.com/tech/thoughts_on_distributed_tracing_system/</link><pubDate>Wed, 31 Mar 2021 10:47:57 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/thoughts_on_distributed_tracing_system/</guid><description> 一切的开始 古早的时候，没人需要分布式追踪系统。大家系统架构简单，功能直来直去，有问题就看日志、查问题。
后来，微服务流行起来。之前的模式，被称作“单体架构”。微服务粒度更小了，以前一个接口做的事，现在要拆散成很多部分，再通过相互调用组合到一起。系统更瘦了，但是管理起来更难了。
当我有 10 个微服务时，出了故障还可以排查。如果有成千上万个微服务呢？随着时间发展，微服务之间的依赖会越来越复杂，一个接口背后可能是几十上百个微服务调用，没人能搞懂了。
大家意识到，需要一个能展示整条调用链路情况的辅助系统。
Google Dapper 这时候，Google 公开了一篇论文 Dapper - a Large-Scale Distributed Systems Tracing Infrastructure，介绍他们的分布式追踪技术。这篇文章提出了科学的分布式追踪模型，仿佛一盏指路明灯，此后几乎所有实现，都遵循这个模型。
基于这篇论文，有了 Zipkin(Twitter 开源), 有了 OpenTracing。国内阿里鹰眼，也在概念上有借鉴。
分布式追踪系统 一般而言，分布式追踪系统分为三部分，采集、上报、落盘与分析。
采集: 对于已经存在大量系统，在代码中进行改造，工作量将相当可观，不现实。明智做法，是从中间件着手，力求侵入更小、开发者无感知。如果是 dubbo 调用，最合适是统一升级 dubbo jar 包。
上报：先把日志打印到本地，然后公共 agent 采集上报。
落盘与存储：数据采集上来后，可以做很多事情。最简单的，放到 HBase + ElasticSearch，支持按 traceId 搜索。复杂点，接入流计算引擎，实时计算相关指标。
我真的需要它吗 直说我的看法：
如果你的系统调用链深度顶多三层，依赖外部系统才一两个，常规日志监控手段足矣，分布式追踪系统并不是必须品。
如果当前你的系统已经按微服务组织起来，但没有使用统一维护的中间件，那应该先改造现有系统，把中间件收敛起来，再统一升级。
不错的参考资料 阿里巴巴鹰眼技术解密 https://www.cnblogs.com/gzxbkk/p/9600263.html
分布式跟踪系统（一）：Zipkin的背景和设计 https://blog.csdn.net/manzhizhen/article/details/52811600</description></item><item><title>使用自定义 Classloader 加载类，利用反射创建实例时出现 NoSuchMethodException</title><link>https://blog.yuantops.com/tech/nosuchmethodexception_when_using_classloader_and_reflection/</link><pubDate>Fri, 08 Jan 2021 17:33:57 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/nosuchmethodexception_when_using_classloader_and_reflection/</guid><description>最近在做一个需求，需要在程序运行时, 从当前 classpath 之外的指定路径加载(已经编译好的)类，并创建它的实例对象。
在程序运行时改变程序结构，本是动态语言的技能点，不是 Java 的强项。但借助 Java 语言 JavaCompiler 与 反射 等动态相关特性，也能勉强做到。 好在就这个需求而言，我们拿到的是编译好的 .class ，不需要编译开始从头做起。
所以我们就从类的动态加载出发，开始做了。 下面是实施步骤，以及遇到的问题。
步骤 我们使用了 Github 上一个可以动态加载 Maven 类的依赖库: ModRun。 将要加载的类所在 jar 包，连同它依赖的 jar 包，按 maven repository 目录结构放置。得到 ModRun 的一个 moduleClassloader。 用 moduleClassLoader 加载类，得到 Class clazz 。 使用反射，调用 clazz.getDeclaredConstructor(xxxType1.class, xxxType2.class) ，得到构建函数。 构建函数调用 invoke(), 传入参数，预期得到所需要的对象。 问题 进行到第 4 步，会报错，提示没有对应的构造函数。但肉眼看上去，同样签名的构造函数明明存在。何故？
分析 在 StackOverflow 搜到答案: StackOverflow 网友回答 。网友回复道: Since class objects depend on the actual class AND on the classloader, they are really different classes。</description></item><item><title>Java 使用指定 classloader 创建 class</title><link>https://blog.yuantops.com/tech/define_class_with_custom_classloader/</link><pubDate>Wed, 06 Jan 2021 11:11:24 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/define_class_with_custom_classloader/</guid><description>有时需要在程序运行时动态创建 Java 类（加载自定义文件，或者是加载 Javassist 之类字节码增强工具创建出来的字节码等）。要注意的是，不同类加载器加载的类，彼此是不可见的，也就不能直接实例化。
要突破这个限制，需要一点 hack: 利用反射机制，在根据字节码创建类时，指定 classloader。下面的代码从著名的 jodd 库摘录，请自行学习。
/** * Defines a class from byte array into the specified class loader. * Warning: this is a &amp;lt;b&amp;gt;hack&amp;lt;/b&amp;gt;! * @param className optional class name, may be &amp;lt;code&amp;gt;null&amp;lt;/code&amp;gt; * @param classData bytecode data * @param classLoader classloader that will load class */ public static Class defineClass(final String className, final byte[] classData, ClassLoader classLoader) { if (classLoader == null) { classLoader = Thread.</description></item><item><title>关于连接池大小</title><link>https://blog.yuantops.com/tech/about_pool_sizing/</link><pubDate>Wed, 09 Dec 2020 16:46:26 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/about_pool_sizing/</guid><description>这篇文章讲得很好，值得一读:
About Pool Sizing https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing
结论 综合CPU核数，磁盘IO，网络状况，得到一个经验公式:
connections = ((core_count * 2) + effective_spindle_count)
A formula which has held up pretty well across a lot of benchmarks for years is that for optimal throughput the number of active connections should be somewhere near ((core_count * 2) + effective_spindle_count). Core count should not include HT threads, even if hyperthreading is enabled. Effective spindle count is zero if the active data set is fully cached, and approaches the actual number of spindles as the cache hit rate falls.</description></item><item><title>artifact存在, 但maven报错: Could not resolve artifact</title><link>https://blog.yuantops.com/tech/maven_cannot_resolve_local_artifact_error/</link><pubDate>Wed, 09 Dec 2020 16:33:48 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/maven_cannot_resolve_local_artifact_error/</guid><description>如果你遇到这个问题，而local repository里jar确实存在，一定看一眼你使用的maven版本：你可能遇到maven 3的一个坑。
简而言之，maven3 开始验证本地仓库jar包的repository_id。
原因 从maven3开始，从远程仓库下载jar包时，会在jar文件旁边生成一个`_maven.repositories`文件，文件里写明它来自哪个repository。
如果当前项目的effective pom(`mvn ` 查看)里，生效的repository列表不包含这个jar包的repository_id，就会 报错 。
解决办法 简单粗暴: 把`_maven.repositories`全删掉
find ~/.m2/repository -name _maven.repositories -exec rm -v {} \; 参考 参考 StackOverflow网友回答 。</description></item><item><title>手工验证一张数字证书的有效性</title><link>https://blog.yuantops.com/tech/validate_a_digital_certificate_step_by_step/</link><pubDate>Sun, 06 Dec 2020 12:17:47 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/validate_a_digital_certificate_step_by_step/</guid><description>上一篇 博客 讨论浏览器验证数字证书的流程。这篇文章更深入一步，用原始方法一步步手工验证证书的合法性。本文主要参考: 回答 与 X.509、PKCS文件格式介绍。
基础名词 ASN.1, DER与PEM ASN.1是一种接口描述语言，它用来定义一种数据结构。
DER是一种编码规则，它用二进制表示ASN.1定义的数据。很多密码学标准使用ASN.1定义数据结构，用DER编码。
但因为DER的内容是二进制的，不方便传输，人们对DER二进制内容进行Base64编码，将其转换为ASCII码，并在头和尾加上标签，就是PEM格式。PEM全称Privacy-Enhanced Mail，起初是为了便于邮件传输，后来在很多场景得到广泛应用。
X.509 X.509是RFC5280定义的一种公钥证书格式(public key certificate)。X.509证书也被称为数字Digital Certificate。一张X.509包含一个Public Key和一个身份信息。X.509证书要么是自签发，要么是被CA签发。
如何得到一张证书 借助浏览器，可以方便导出数字证书。
打开chrome，访问本博客网址(https://blog.yuantops.com)，地址栏最左侧有个小锁图案 —— 这是网站受到HTTPS加密保护的标志。
在&amp;rdquo;Details&amp;rdquo;标签，观察&amp;rdquo;Certificate Subject Alternative Name&amp;rdquo;字段，值包含&amp;rdquo;DNS Name: yuantops.com&amp;rdquo; &amp;ldquo;DNS　Name: *.yuantops.com&amp;rdquo;，说明证书的确属于这个域名。
点击小锁　-&amp;gt; &amp;ldquo;certificate&amp;rdquo; -&amp;gt; &amp;ldquo;Details&amp;rdquo; -&amp;gt; &amp;ldquo;Export&amp;hellip;&amp;ldquo;，可以选择证书的导出格式。
选择&amp;rdquo;Base64-encoded ASCII, single certificate&amp;rdquo;，得到一张PEM格式证书。将它保存为`sni.cloudflaressl.com`。
-----BEGIN CERTIFICATE----- MIIEwzCCBGmgAwIBAgIQDVZy4W9/IjNEOZEGQ2ADTjAKBggqhkjOPQQDAjBKMQsw CQYDVQQGEwJVUzEZMBcGA1UEChMQQ2xvdWRmbGFyZSwgSW5jLjEgMB4GA1UEAxMX Q2xvdWRmbGFyZSBJbmMgRUNDIENBLTMwHhcNMjAwODA3MDAwMDAwWhcNMjEwODA3 MTIwMDAwWjBtMQswCQYDVQQGEwJVUzELMAkGA1UECBMCQ0ExFjAUBgNVBAcTDVNh biBGcmFuY2lzY28xGTAXBgNVBAoTEENsb3VkZmxhcmUsIEluYy4xHjAcBgNVBAMT FXNuaS5jbG91ZGZsYXJlc3NsLmNvbTBZMBMGByqGSM49AgEGCCqGSM49AwEHA0IA BCh3/Sz4YWHFP32cBLzErjTKy4/AdFKU37wFK8kzP7sdhM3/BxdJNKeRYNwcDimw k76zgHaaGki0AzvCTMa+llWjggMMMIIDCDAfBgNVHSMEGDAWgBSlzjfq67B1DpRn iLRF+tkkEIeWHzAdBgNVHQ4EFgQUi9pqgIAX5apgTXwOGZ9k1FALDL0wPgYDVR0R BDcwNYIOKi55dWFudG9wcy5jb22CFXNuaS5jbG91ZGZsYXJlc3NsLmNvbYIMeXVh bnRvcHMuY29tMA4GA1UdDwEB/wQEAwIHgDAdBgNVHSUEFjAUBggrBgEFBQcDAQYI KwYBBQUHAwIwewYDVR0fBHQwcjA3oDWgM4YxaHR0cDovL2NybDMuZGlnaWNlcnQu Y29tL0Nsb3VkZmxhcmVJbmNFQ0NDQS0zLmNybDA3oDWgM4YxaHR0cDovL2NybDQu ZGlnaWNlcnQuY29tL0Nsb3VkZmxhcmVJbmNFQ0NDQS0zLmNybDBMBgNVHSAERTBD MDcGCWCGSAGG/WwBATAqMCgGCCsGAQUFBwIBFhxodHRwczovL3d3dy5kaWdpY2Vy dC5jb20vQ1BTMAgGBmeBDAECAjB2BggrBgEFBQcBAQRqMGgwJAYIKwYBBQUHMAGG GGh0dHA6Ly9vY3NwLmRpZ2ljZXJ0LmNvbTBABggrBgEFBQcwAoY0aHR0cDovL2Nh Y2VydHMuZGlnaWNlcnQuY29tL0Nsb3VkZmxhcmVJbmNFQ0NDQS0zLmNydDAMBgNV HRMBAf8EAjAAMIIBBAYKKwYBBAHWeQIEAgSB9QSB8gDwAHYA9lyUL9F3MCIUVBgI MJRWjuNNExkzv98MLyALzE7xZOMAAAFzyS9NoAAABAMARzBFAiB5au5KCRfkyBcI 7jECy/NvNPkKEoMUUTwZP+rZbHtn8AIhAKOR2Lh2zsCw+gy38abKie1fyd1rmm0c GA/pP6PykChvAHYAXNxDkv7mq0VEsV6a1FbmEDf71fpH3KFzlLJe5vbHDsoAAAFz yS9N0wAABAMARzBFAiALkQMvm51FKVO2JRFiWWEgqu4x9rGHy2JH6P2m18lrLQIh AN1PcRtCiY+gihkncncx18OZM6e5CGZruk05EDGThLTvMAoGCCqGSM49BAMCA0gA MEUCIHXeLOwERMHY88NliKhUzs1MwoJap9sNm9qQLGXYCpEMAiEA1ZsGvWxusXK9 tAgwUjlWi5Ke5rvM/i01sYl6bpls4Z0= -----END CERTIFICATE----- 分析证书结构 RFC5280规定了X.</description></item><item><title>浏览器验证SSL数字证书的步骤</title><link>https://blog.yuantops.com/tech/how_do_web_broswer_validate_ssl_certificates/</link><pubDate>Tue, 24 Nov 2020 09:07:26 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/how_do_web_broswer_validate_ssl_certificates/</guid><description>浏览器和服务器使用SSL/TLS通信时，双方首先要通过几次握手(Handshake)，建立加密信道。简单说来，分为下面３步:
服务器发送自己的SSL证书； 浏览器验证服务器SSL证书； 证书验证成功，双方协商得到对称加密密钥，并交换。双方拿到对称加密密钥后，后续的通信都会用它做对称加密。 本文介绍的重点，在前２步。首先，转载一篇国外博客，讲述浏览器检查证书的过程；其次，会引述两个RFC协议的相关内容；最后，wireshark抓包进行验证。
Browsers and Certificate Validation 原文地址: https://www.ssl.com/article/browsers-and-certificate-validation/
使用DeepL 翻译成中文，如下:
## 证书和X.509格式 证书在各方面都是数字文件，这意味着它们需要遵循一种文件格式来存储信息（如签名、密钥、签发人等）。虽然私有的PKI配置可以为其证书实现任何格式，但公共信任的PKIs（即那些被浏览器信任的PKIs）必须符合RFC 5280，这就要求使用X.509 v3格式。 X.509 v3允许证书包含额外的数据，如使用限制或策略信息，作为扩展，每个扩展都是关键或非关键的。浏览器可以忽略无效的或未被识别的非关键扩展，但它们必须处理和验证所有关键扩展。 ## 认证路径和路径处理 憑證機構使用私人密碼匙對所有簽發的證書進行加密簽署。这种签名可以不可撤销地证明证书是由某一特定的核证机 构签发的，而且在签署后没有被修改。 CA通过持有相应公钥的自发证书（称为根）来建立其签名密钥的所有权。憑證機構必須遵守嚴格的控制和審核程序來建立、管理和使用根證書，為了減少暴露，通常會使用根證書來簽發中間證書。这些中间证书可以用来签发客户的证书。 浏览器在出厂时都有一个内置的可信根列表。(这些根是来自通过浏览器严格标准的CA的根。) 为了验证证书，浏览器将获得一个证书序列，每个证书都签署了序列中的下一个证书，将签名CA的根与服务器的证书连接起来。 这个证书序列称为认证路径。路径的根部称为信任锚，服务器的证书称为叶子或终端实体证书。 ### 路径的构造 通常情况下，浏览器必须考虑多个认证路径，直到他们能够为给定证书找到一个有效的路径。即使一个路径可能包含的证书可以正确地 &amp;quot;链 &amp;quot;到一个已知的锚，但由于路径长度、域名、证书使用或政策的限制，路径本身可能会被拒绝。 对于浏览器遇到的每一个新证书，构建和评估所有可能的路径都是一个昂贵的过程。浏览器已经实现了各种优化，以减少被拒绝的候选路径的数量，但深入探讨这些细节已经超出了本文的范围。 ### 路径验证 候选认证路径构建完成后，浏览器使用证书中包含的信息对其进行验证。如果浏览器能够通过密码学的方式证明，从一个信任锚直接签署的证书开始，每个证书对应的私钥都被用来签发路径中的下一个证书，一直到叶子证书，那么这个路径就是有效的。 ## 认证路径验证算法 RFC 5280描述了浏览器验证X.509证书认证路径的标准算法。 基本上，浏览器从信任锚（即根证书）开始，遍历路径中的所有证书，验证每张证书的基本信息和关键扩展。 如果该过程以路径中的最后一张证书结束，没有错误，那么该路径被接受为有效。如果产生错误，则该路径被标记为无效。 ### 证书的基本处理 无论是否有任何扩展，浏览器必须始终验证基本的证书信息，如签名或签发人。下面的章节显示了浏览器执行检查的顺序。 1. 浏览器验证证书的完整性 证书上的签名可以用正常的公用钥匙加密法进行验证。如果签名无效，则认为该证书在签发后被修改，因此被拒绝。 2. 浏览器验证证书的有效性： 證書的有效期是指簽署憑證機構保證會維持其狀態資訊的時間間隔。浏览器会拒绝任何有效期在验证检查日期和时间之前或之后开始的证书。 3. 浏览器检查证书的撤销状态。 证书签发后，应该在整个有效期内使用。当然，在各种情况下，证书可能会在自然到期前失效。 这类情况可能包括主体改名或怀疑私钥泄露。在这样的情况下，CA需要撤销相应的证书，而用户也信任CA会通知浏览器其证书的撤销状态。 RFC 5280建议CA使用撤销列表来实现这一目的。 证书废止列表(CRL) 核證機關會定期發出一份經簽署、有時間標記的廢止證書清單，稱為證書廢止清單（CRL）。CRL分布在公开的存储库中，浏览器在验证证书时可以获得并查阅CA的最新CRL。 这种方法的一个缺陷是，撤销的时间粒度仅限于CRL的发布期。只有在所有当前已发布的CRL都被安排更新后，浏览器才会收到撤销的通知。根据签名CA的政策，这可能需要一个小时、一天甚至一周的时间。 在线证书状态协议(OCSP) 还有其他的方法来获取废止状态信息，其中最流行的是在线证书状态协议（OCSP）。 OCSP在标准文档RFC6960中进行了描述，它允许浏览器从在线OCSP服务器（也称为回复者）请求特定证书的撤销状态。如果配置得当，OCSP的即时性更强，而且避免了上面提到的CRL更新延迟问题。此外，OCSP Stapling还能提高性能和速度。 4. 浏览器验证发件人 证书通常与两个实体相关联。 签发人，也就是拥有签名密钥的实体，以及 主体，指的是证书认证的公钥的所有者。 浏览器会检查证书的签发人字段是否与路径中前一个证书的主题字段相同。为了增加安全性，大多数PKI实现也会验证发证者的密钥是否与签署当前证书的密钥相同。(请注意，这对于信任锚来说并不正确，因为根是自发的--即它们具有相同的签发人和主体)。 约束处理 X.</description></item><item><title>浏览器会处理URL里的相对路径</title><link>https://blog.yuantops.com/tech/how_web_broswer_handles_url_relative_path/</link><pubDate>Thu, 21 Nov 2019 15:53:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/how_web_broswer_handles_url_relative_path/</guid><description>新系统上线前，安全部门扫描出一个高危漏洞：文件任意下载漏洞。渗透测试人员在URL里加上相对路径，不断发起HTTP请求，居然成功下载到Linux系统密码文件。修复漏洞挺简单，限制HTTP服务访问文件系统权限，不允许超出指定目录，几行代码搞定。
修复之后准备进行验证，第一步当然是复现漏洞。没想到，这一步就挺曲折。
消失的点号 打开chrome，在地址栏输入带了相对路径( .. )的URL。URL指向一个文件，理论上，会触发文件下载。结果是：地址栏URL路径里点号全不见了，变成了一个正常地址。多试几遍，把双点号换成单点号，仍然如此。用 wiresharks 抓包看HTTP报文，请求头 path 没有点号。这说明，浏览器做了手脚。
Google搜之，找到一份解析URI的RFC3968标准，专门有一章论述解析点号：Remove Dot Segments。经过解析，点号和双点号会消失，这个过程被称为 remove_dot_segments 。(RFC3968给出了这个过程的伪代码。)
Google官方在一篇文章里，将Chrome解析URL的过程称为 `Canonicalization` (display-urls-in-canonical-form) 。经过解析，Chrome地址栏的点号变成实际值。
结合两篇文档，原理清楚了：浏览器遵循RFC3968规范处理URL相对路径，所以点号和双点号都被干掉了。
改用Burp Suite重现问题 不能用浏览器复现问题，改尝试 curl 命令。结果，curl也不能复现。好在可以借助 Burp Suite 工具。
Burp Suite是一款攻击web服务的集成工具，一般黑客用它来渗透网络。我们牛刀小用，用来拦截、修改HTTP请求报文。过程不在此赘述。总之，用它绕过了相对路径解析、重现了漏洞。
修复漏洞 略。</description></item><item><title>How to blog with ox-hugo in Emacs</title><link>https://blog.yuantops.com/tech/blogging-with-ox-hugo/</link><pubDate>Thu, 25 Jul 2019 14:47:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/blogging-with-ox-hugo/</guid><description>我的一篇老博客，介绍了用Emacs和Org-mode写博客的工作流。总的来说，勉强符合预期，流程稍显磕绊。今天偶然发现，用Org-mode写博客有了正规军： ox-hugo 。简单试用之后,发现 ox-hugo 表现很流畅，几乎就是对之前流程的升级，于是毫不犹豫选 ox-hugo 。
安装 ox-hugo 是一个工作在Org-mode的Emacs包，安装过程可以说平平无奇：
M x package-refresh-contents :: 更新安装源 添加Emacs配置。修改细节与Emacs配置风格相关，我使用Purcell维护的.emacs.d配置，仅供参考。
在 .emacs.d/lisp/ 目录下，新增配置文件 init-ox-hugo.el
1 2 3 4 5 6 7 (require-package &amp;#39;ox-hugo)
(with-eval-after-load &amp;#39;ox (require &amp;#39;ox-hugo))
(provide &amp;#39;init-ox-hugo)
在入口配置文件 .emacs.d/init.el 中，引用新增的配置文件
(require &#39;init-ox-hugo) 写博客旧流程 现在，org文件可以直接导出为Hugo支持的Markdown格式了。这一点 ox-pandoc 也能做到，但 ox-hugo 还能做得更多。
回顾之前的工作流:
新建xx.org文件 输入二级标题，接着插入 front matter 。 front matter 内容大致如下：
+++ title = &amp;quot;&amp;quot; date = &amp;quot;&amp;quot; Categories = [&amp;quot;Tech&amp;quot;] Tags = [&amp;quot;Emacs&amp;quot;] Description = &amp;quot;&amp;quot; keywords = [&amp;quot;&amp;quot;] +++ 写博客正文</description></item><item><title>Bash Guideline Notes</title><link>https://blog.yuantops.com/tech/bash-guideline-study-notes/</link><pubDate>Thu, 25 Jul 2019 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/bash-guideline-study-notes/</guid><description>关于重定向顺序 Note that the order of redirections is signi cant. For example, the command ls &amp;gt; dirlist 2&amp;gt;&amp;amp;1 directs both standard output ( file descriptor 1) and standard error ( le descriptor 2) to the file dirlist, while the command ls 2&amp;gt;&amp;amp;1 &amp;gt; dirlist directs only the standard output to file dirlist, because the standard error was made a copy of the standard output before the standard output was redirected to dirlist.</description></item><item><title>Understanding XOR</title><link>https://blog.yuantops.com/tech/understanding-xor/</link><pubDate>Thu, 25 Jul 2019 00:00:00 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/understanding-xor/</guid><description>We can interpret the action of XOR in a number of different ways, and this helps to shed light on its properties. The most obvious way to interpret it is as its name suggests, ‘exclusive OR’: A ⊕ B is true if and only if precisely one of A and B is true. Another way to think of it is as identifying difference in a pair of bytes: A ⊕ B = ‘the bits where they differ’.</description></item><item><title>[译文]让Siri变身完美家庭助手：兼容Apple Homekit不支持的设备</title><link>https://blog.yuantops.com/tech/homebridge-plugin-tutorial/</link><pubDate>Sun, 29 Jul 2018 17:48:19 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/homebridge-plugin-tutorial/</guid><description>译文一篇, 原文地址：http://blog.theodo.fr/2017/08/make-siri-perfect-home-companion-devices-not-supported-apple-homekit/ 。
Apple推出Homekit已有一段时间，作为智能家具解决布局的重要一环，Homekit在中文互联网上的资料可算寥寥。这篇文章介绍了Homekit平台抽象的关键概念，以及Homebridge这一款破解了Homekit协议、并支持插件化开发扩展的优秀程序。
文章还包含了一个详细教程，一步步教你写简单的Homebridge插件。
即使不是开发者，读完这篇文章，最起码可以让你打开iOS “家庭”应用时不至于一头雾水。
========================分割线，以下是正文===============================
为什么是Homekit? Homekit是Apple开发的家庭配件管理框架。有了Homekit，Apple设备用户可以使用同一套界面，管理不同厂商的接入设备。它使Siri变得更强，能听懂发给这些设备的指令。
如果你有一部iPhone或者Apple TV，Homekit可以在Home Assistant等互联协议的基础上做更多好玩的事。iPhone原生支持Homekit，你可以通过&amp;rdquo;家庭&amp;rdquo;app 或者快速访问标签，方便地管理设备。Apple TV则可以作为设备中枢，让你设置自动化任务，并且让你在非家庭网络下也能掌控家中情况。
工作原理 Homekit Accessory Protocol Homekit为家庭和各种连接设备定义了一组布局(layout)：
家庭(Home)：家庭是一处住所，它有一个由各种配件组成的网络。 房间(Room)：每个家庭有一个或多个房间，每个房间有一个或多个配件。 平台(Platform)：平台指的是一组配件。 配件(Accessory)：配件指的是一台支持自动化的物理设备。 桥(Bridge)：桥是一种特殊配件，通过它可以和那些不能与Homekit直接通信的配件通信。举例来说，桥可能是一个灯光的中枢，灯光之间通信时并不使用Homekit Accessory Protocol协议。 服务(Service)：一个服务对应配件的一种功能。车库门除了提供开关门的服务，还可能额外提供开关车库灯的服务。 特征(Characteristic)：每个服务都有一些被称为特征的属性。对车库门而言，它有 Current Door State 和 Target Door State 两个boolean值。服务的所有特征共同定义了它的当前状态。特征有3种权限：读，写，通知。这里能找到各种服务列表，以及与之关联的特征。 为了确定要操作的设备以及要触发的动作，iOS的&amp;rdquo;家庭&amp;rdquo;应用和Siri发出的每一个请求，都会使用上面的布局。
然而，当前市面上只有少量设备支持Homekit。对其他设备来说，需要在Homekit和设备间设置一个代理(proxy)。大多数厂商会自己定义一套与设备交互的方式(API或者协议)。代理接收Homekit请求，然后将它们翻译成设备能听懂的语言。
Homebridge 本文使用的代理是Homebridge，一款用HAP-node.js写的NodeJS服务器。Homebridge实例化出一个 桥 ，然后你用iOS的&amp;rdquo;家庭&amp;rdquo;应用把它添加到Homekit。Homebridge支持社区开发的插件，从而在Homekit和五花八门的&amp;rdquo;智能家居&amp;rdquo;设备间建立连接。
社区开发者已经为很多家庭自动化设备开发了插件(例如Nest, Lifx, 甚至是所有兼容Home Assitant的设备)。如果你没找到要找的插件，这篇教程正是为你而写。
自己开发插件 要求 你已经在LAN中一台设备上安装了Homebridge，而且处于运行状态。参考这些教程。 你已经在iOS的&amp;rdquo;家庭&amp;rdquo;应用中，添加了Homebridge配件。 教程 我们来动手写一个假的开关插件。
新建一个目录，包含2个文件：管理依赖的 package.json 文件，以及放插件核心逻辑的 index.js 文件。
我们对开关API的设定如下：
在LAN里，能通过HTTP协议层的RESTful API控制它 在LAN里，开关的IP地址是192.168.0.10 对 /api/status 的GET请求返回一个boolean值，代表开关的当前状态。这个请求会读取开关的 On 特征 对 /api/order 的POST请求里携带一个代表开关目标的boolean值，将触发对应动作。这个请求会写入开关的 On 特征 这个Homebridge插件将提供一个新配件，包含两个服务：</description></item><item><title>树莓派连接DHT11温度湿度传感器</title><link>https://blog.yuantops.com/tech/rasp-pi-dht11/</link><pubDate>Sat, 28 Jul 2018 20:30:45 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/rasp-pi-dht11/</guid><description>记录一下给树莓派安装温度湿度传感器的过程。
树莓派主板有一排GPIO扩展口，可以方便地驱动硬件。温度湿度传感器DHT11是一种常见传感器，很适合作为入门器件，探索树莓派的硬件能力。
我上次接触硬件知识还是在大二的单片机小学期，几乎已经忘光，正好趁机抢救性回忆一下。
目标 在树莓派上读到温度和湿度数据。
元件清单 除了传感器DHT11，还需要连接线、面包板等元件，在淘宝上很好买到。
我额外买了一块树莓派特制GPIO扩展板，用它把树莓派的40根针脚延长到面包板，类似USB延长线。很怀疑这是来自中国的&amp;rdquo;微创新&amp;rdquo;，值得赞美，因为确实解决了树莓派针脚空间狭小不便于插线的小痛点。
下面是元件清单：
树莓派Model 3 B
DHT11传感器。我用的是三脚型号。
面包板
杜邦线/连接线
插线 在实际插线之前，有必要先来认识树莓派针脚。树莓派3代一共40根针脚，这么辨认物理编号：横着放，让2排针脚在上面，上面那排是偶数，从左到右是2到40；下面那排是奇数，从左到右是1到39。
40根针脚里，有28根GPIO针脚。这28根针脚，又有两种命名规则：BCM编号，WiringPi编号。还要注意，树莓派2代和3代的对应关系不一样，参考网上资料时要看清针脚图的型号。
BCM编号，就是我们常看见的 GPIOxx 里面的 xx 。 WiringPi编号，是 WiringPi库 使用的编号。除非是用WiringPi库驱动针脚，否则不需关注。 对我这样的新手而言，最初物理编号和BCM编号两套规则切换起来有些烦人，需要一些细心。
下面的接线方案，用的是物理编号：
左边 + 接3.3V电源，选择 1 口。 中间 DATA ，选择 7 口。 右边 - 接地，选择 14 口。 安装命令 DHT11是非常成熟通用的传感器，对它的驱动封装也特别多，不需再造轮子。货比三家，我发现Adafruit公司开源的代码质量最高，运行起来最稳定。
安装Adadruit公司的开源库：Adafruit Python DHT
在安装目录下, 进入example目录，运行 AdafruitDHT.py 文件:
pi@raspberrypi:~/Adafruit_Python_DHT/examples $ python AdafruitDHT.py 0 30.</description></item><item><title>Go从GitHub安装命令时指定commit/tag</title><link>https://blog.yuantops.com/tech/go-install-cmd-on-specific-git-tag/</link><pubDate>Mon, 14 May 2018 09:49:03 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/go-install-cmd-on-specific-git-tag/</guid><description>Go的版本管理是一大痛点，最近我就亲身经历了一遭。在Blog自动部署实践一文中，我把部署博客的工作流交给了Travis CI。第二天，我照例打开Google Analytics查看访问量，发现前一天的访问量跌到0：一定出了什么问题。
我从GitHub上把 gh-pages 分支pull下来，grep我的Google Analysis跟踪码，居然没有。在本地用 hugo 命令生成静态文件，在public目录里发现每篇文章的html页面都包含Google Analytics跟踪代码。到此基本确定问题：Travis CI build生成的静态网页货不对版，因为默认使用最新版本 hugo 命令，所以绝对是 hugo 版本更新导致的兼容问题。
解法也很简单，在 .travis.yml 文件里安装指定版本的 hugo 命令，让它和我本地hugo命令的版本号保持一致。
.travis.yml 用go get安装Go命令。虽然官方不支持指定commit，但我在Stackoverflow:How to do “go get” on a specific tag of a github repository 上找到了曲线救国方法，摘录如下：
1. Run the get command without the tag - it should clone the master branch. 2. Move to the clone directory and checkout the tag or branch that you want. 3. Run the go get command again, it should process the command on the checked out branch.</description></item><item><title>本博客现已支持HTTPS</title><link>https://blog.yuantops.com/tech/announcement-blog-https-supported/</link><pubDate>Sat, 12 May 2018 12:59:10 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/announcement-blog-https-supported/</guid><description>赶个晚集，给博客加上了HTTPS支持。现在以http://访问博客，会自动跳转到https://。
感谢Cloudflare提供的福利，让个人博客也能免费享受SSL。</description></item><item><title>Blog自动部署实践: Hugo &#43; Travis CI -&gt; GitHub Pages</title><link>https://blog.yuantops.com/tech/hugo-travis-ci-auto-deploy-to-gh-pages/</link><pubDate>Sat, 12 May 2018 08:45:52 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/hugo-travis-ci-auto-deploy-to-gh-pages/</guid><description>这个博客托管在GitHub Pages上已经有一段时间。最初使用的静态站点生成工具是Jekyll，后来换成Hugo，因为是免费，一直都还比较满意。只有一个小痛点，博客从写完到部署的步骤多：写文章 -&amp;gt; build -&amp;gt; deploy…
我之前写过一篇用Emacs写博客的workflow，把&amp;rdquo;写文章&amp;rdquo;的流程优化了一把。之后又小打小闹，用GitHub的webhook做了一个commit message关键字触发的小服务，把&amp;rdquo;build&amp;rdquo;和&amp;rdquo;deploy&amp;rdquo;做成自动化。这个服务跑在免费的Google Cloud上，使用体验还不错，可惜主机没续费，服务直接停掉，源码也丢失了。
随手Google一把GitHub Page的持续集成，才后知后觉地发现自己想要的东东已经有了成熟解决方案，而且还可以 免费 用：Travis CI。于是我颇愉快地接受它，并简单地在这里记录下来。
什么是Travis CI 一个持续化集成平台，类似Jenkins。功能强大，和GitHub的集成尤其好，我们用它部署个人博客算大材小用。它有两个版本:
https://travis-ci.org/ 免费版本，可以集成GitHub的public项目 https://travis-ci.com/ 商业版本，可以集成GitHub的private项目 我们使用第一个，免费版本。
本博客现状回顾 在进一步描述具体步骤之前，有必要先简要回顾本博客的现状：
用Hugo生成静态站点文件 两个git分支, hugo: 存放博客源码, gh-pages: 存放Hugo生成的静态站点文件 自定义域名: `blog.yuantops.com`, 而不是默认的yuantops.github.io 配置Travis CI 为Travis CI生成GitHub Token 打开GitHub。路径: &amp;ldquo;Settings&amp;rdquo;-&amp;gt;&amp;ldquo;Developer settings&amp;rdquo;-&amp;gt;&amp;ldquo;Personal access tokens&amp;rdquo;-&amp;gt;&amp;ldquo;Generate new token&amp;rdquo;。
因为是public项目，而且Travis CI是用来push代码，所以只需勾选 public_repo, repo:status, repo_deployment 三项。
Token一会儿就会隐藏，不能找回，所以拷贝好，进入下一步。
配置Travis CI构建选项 用GitHub方式登录Travis CI(https://travis-ci.org/) &amp;ldquo;Settings&amp;rdquo;-&amp;ldquo;General&amp;rdquo; 勾选&amp;rdquo;Build only if .travis.yml is present&amp;rdquo;和&amp;rdquo;Build pushed branches&amp;rdquo;两项。 &amp;ldquo;Settings&amp;rdquo;-&amp;ldquo;Environment Variables&amp;rdquo; 添加&amp;rdquo;GITHUBTOKEN&amp;ldquo;，值是上一步得到的Token 在git根目录下添加 .</description></item><item><title>用Benchmark验证sync.Pool对GC latency的优化效果</title><link>https://blog.yuantops.com/tech/sync-pool-benchmark/</link><pubDate>Fri, 11 May 2018 10:33:25 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/sync-pool-benchmark/</guid><description>可能是为了避免重复造轮子，Go官方库推出了sync.Pool:一个thread-safe、可回收/重用对象的内存池。对性能优化狂魔而言，sync.Pool无疑是一个优化GC的好工具，因为理论上重用对象会减少了GC次数，缩短latency。这篇文章是sync.Pool的性能验证报告：sync.Pool确实能极大减少GC次数。
Benchmark关注什么？ 在写Benchmark代码之前，要先确定如何衡量GC效果。很直观地，GC次数越少，效果越好。但GC次数的粒度太大，说服力不够，还需要其他的指标。
这篇文章Golang real time gc 给我了答案。不断往一个size固定的buffer里覆盖写入数据，记录写入耗时。被覆盖掉的数据会变成垃圾，继而触发GC，所以耗时就是latency。
原文引述如下：
The benchmark program repeatedly pushes messages into a size-limited buffer. Old messages constantly expire and become garbage. 于是，Benchmark的实现，以及关注的指标就确定了：
GC次数 数据写入耗时 代码实现 不用sync.Pool的实现 见https://play.golang.org/p/049Xmy1lTfV
package main import ( &amp;quot;fmt&amp;quot; &amp;quot;time&amp;quot; ) const ( windowSize = 200000 msgCount = 100000000 ) type ( message []byte buffer map[int]message ) var worst time.Duration func mkMessage(n int) message { m := make(message, 1024) for i := range m { m[i] = byte(n) } return m } func pushMsg(b *buffer, highID int) { start := time.</description></item><item><title>Emacs Golang开发环境配置指南</title><link>https://blog.yuantops.com/tech/emacs-config-go-dev-environ/</link><pubDate>Thu, 04 Jan 2018 00:31:08 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/emacs-config-go-dev-environ/</guid><description>安装Go 虽然像是废话，但为了配置过程的完整性，还是记下来吧。
官网install链接: https://golang.org/doc/install
装好后记得配置 $GOPATH 。为了能在任何地方使用Go编译出来的命令，还可以把 $GOPATH/bin 附到环境变量$PATH。
我在Mac上使用iTerm2+oh-my-zsh，所以把它们写到 .zshrc :
# go path export GOPATH=~/go # add go commands to system path export PATH=$GOPATH/bin:$PATH 让go get命令绕过Great Wall的束缚 有了Go的开发环境，我们就可以用它编译、安装一些十分有用的小命令了。但在此之前，还有一些客观存在的技术障碍需要扫除。
一般 go get 命令会自动帮我们下载源码、编译、安装命令，如果托管源码的网站被block了(如gopkg.in)，整个过程就会卡住，卡到人抓狂(记得在内心f**k GFW哦~)。
这时，如果电脑上刚好运行着shadowsocks，事情就变得简单了。go get 支持http_proxy和https_proxy，我们需要动一点手脚，把sock5协议转换成http协议。
(以下步骤的前提是电脑上运行着shadowsocks。)
安装 polipo
brew install polipo 配置 polipo 在家目录下新建 .polipo 文件，内容如下:
#必填 socksParentProxy = &amp;quot;localhost:1080&amp;quot; socksProxyType = socks5 运行 polipo
polipo &amp;amp; 默认会监听8123端口的http请求。
在go get命令前加上http_proxy参数</description></item><item><title>Orgmode利用ox-pandoc导出hugo博客的workflow</title><link>https://blog.yuantops.com/tech/emacs-orgmode-hugo-with-oxpandoc/</link><pubDate>Sun, 10 Dec 2017 13:16:22 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/emacs-orgmode-hugo-with-oxpandoc/</guid><description>使用Emacs有一年多了吧，终于开始体会到它的强大。这段盘旋上升的磨合期，值得写几篇文章记录一下。这篇博客就是我用orgmode + hugo写博客的个人实践，希望对orgmode中文用户/hugo blogger有所启发。
之前的workflow 自从转到hugo后，我发博客的workflow是这样的：
在org文件里添加内容 按下 C-c C-e （export命令），再按 C-s (只导出当前subtree)，再按 m o (导出格式markdown)，生成markdown 内容 把markdown内容保存到 hugo/content/ 目录，手动加上文件头(front matter) 本地部署hugo server，检查效果。无误则运行部署脚本 deploy.sh push到github仓库的 hugo 分支 github上我给 hugo 分支加了webhook，会触发构建，部署生成的html内容到 gh-pages 分支 这段流程一直还凑合，直到我的博客里出现表格：org导出的markdown表格会变成一坨翔，我要在第4步浪费很多时间人肉调整格式。
怒google一把，发现是org markdown官方导出引擎不支持table导致的:
Since md is built on top of the HTML back-end, any Org constructs not supported by Markdown, such as tables, the underlying html back-end (see HTML export) converts them. 搜索时我发现有网友提到 ox-pandoc ，点进去github主页看了看，pandoc和orgmode的天作之合啊。pandoc对表格的支持无懈可击，还有啥好说，马上就决定是它了！</description></item><item><title>Emacs macOS配置中文字体</title><link>https://blog.yuantops.com/tech/emacs-macos-chn-font-conf/</link><pubDate>Sun, 10 Dec 2017 00:50:07 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/emacs-macos-chn-font-conf/</guid><description> 从网上攒来的emacs字体配置地址
https://github.com/yuantops/emacs.d/blob/universal/lisp/init-fonts.el
列出系统提供的所有字体
参考链接 http://cnborn.net/blog/2014/10/emacs-chinese-font-on-osx/
(print (font-family-list)) 找到中文字体，添加到chn font list 开头</description></item><item><title>sed和awk学习笔记</title><link>https://blog.yuantops.com/tech/sed_awk_notes/</link><pubDate>Sat, 09 Dec 2017 17:12:59 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/sed_awk_notes/</guid><description>为什么加上单引号: 防止shell expansion
Enclosing the instruction in single quotes is not requir ed in all cases but you should get in the habit of always doing it. The enclosing single quotes prevent the shell from interpreting special characters or spaces found in the editing instruction.(The shell uses spaces to determine individual arguments submitted to a program;characters that are special to the shell are expanded before the command is invoked.</description></item><item><title>《Maven实战》摘抄</title><link>https://blog.yuantops.com/tech/maven-in-action-notes/</link><pubDate>Tue, 28 Nov 2017 19:16:30 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/maven-in-action-notes/</guid><description>关键词 “约定优于配置” Convention Over Configuration 生命周期管理 依赖管理：GAV坐标+scope 术语翻译 英文 中文 artifact 构件 build 构建 project 项目 group 组 module 模块 archetype 骨架 dependency mediation 依赖调解 repository 仓库 phase 阶段 aggregation 聚合 reactor 反应堆 property 属性 关于主代码和测试代码位置 在绝大多数情况下，应该把项目主代码放到src/main/java 目录下(遵循Maven的约定)，而无需额外的配置，Maven会自动搜寻该目录找到项目主代码。其次，该Java类的包名是com.</description></item><item><title>MyBatis generator生成Dao和Mapper小记</title><link>https://blog.yuantops.com/tech/mybatis-mbg-cmd/</link><pubDate>Tue, 17 Oct 2017 10:30:53 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/mybatis-mbg-cmd/</guid><description>需下载文件 Mybatis Generator jar包
下载地址 https://mvnrepository.com/artifact/org.mybatis.generator/mybatis-generator-core
JDBC 驱动jar 包
对MySQL数据库而言，下载MySQL connector。下载地址 https://mvnrepository.com/artifact/mysql/mysql-connector-java
配置config.xml config.xml 文件指定自动生成代码时的一些配置项：数据库的url, 用户名密码，生成类名、导出地址等。
数据库url, 用户名，密码是最重要的配置。
下面是示例：
&amp;lt;?xml version=&amp;quot;1.0&amp;quot; encoding=&amp;quot;UTF-8&amp;quot;?&amp;gt; &amp;lt;!DOCTYPE generatorConfiguration PUBLIC &amp;quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&amp;quot; &amp;quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&amp;quot;&amp;gt; &amp;lt;generatorConfiguration&amp;gt; &amp;lt;!--数据库驱动, 注意jar包版本号与实际下载的版本号一致--&amp;gt; &amp;lt;classPathEntry location=&amp;quot;mysql-connector-java-3.1.13.jar&amp;quot;/&amp;gt; &amp;lt;context id=&amp;quot;DB2Tables&amp;quot; targetRuntime=&amp;quot;MyBatis3&amp;quot;&amp;gt; &amp;lt;commentGenerator&amp;gt; &amp;lt;property name=&amp;quot;suppressDate&amp;quot; value=&amp;quot;true&amp;quot;/&amp;gt; &amp;lt;property name=&amp;quot;suppressAllComments&amp;quot; value=&amp;quot;true&amp;quot;/&amp;gt; &amp;lt;/commentGenerator&amp;gt; &amp;lt;!--数据库链接地址账号密码, 更新此处--&amp;gt; &amp;lt;jdbcConnection driverClass=&amp;quot;com.mysql.jdbc.Driver&amp;quot; connectionURL=&amp;quot;jdbc:mysql://xx.xxx.xxx.xx:36360/?characterEncoding=UTF-8&amp;quot; userId=&amp;quot;xxx&amp;quot; password=&amp;quot;xxx&amp;quot;&amp;gt; &amp;lt;/jdbcConnection&amp;gt; &amp;lt;javaTypeResolver&amp;gt; &amp;lt;property name=&amp;quot;forceBigDecimals&amp;quot; value=&amp;quot;false&amp;quot;/&amp;gt; &amp;lt;/javaTypeResolver&amp;gt; &amp;lt;!--生成Model类存放位置--&amp;gt; &amp;lt;javaModelGenerator targetPackage=&amp;quot;domain&amp;quot; targetProject=&amp;quot;src&amp;quot;&amp;gt; &amp;lt;property name=&amp;quot;enableSubPackages&amp;quot; value=&amp;quot;true&amp;quot;/&amp;gt; &amp;lt;property name=&amp;quot;trimStrings&amp;quot; value=&amp;quot;true&amp;quot;/&amp;gt; &amp;lt;/javaModelGenerator&amp;gt; &amp;lt;!</description></item><item><title>整理Java有限状态机</title><link>https://blog.yuantops.com/tech/fsm_and_java_implementation/</link><pubDate>Thu, 12 Oct 2017 14:30:53 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/fsm_and_java_implementation/</guid><description>有限状态机FSM及它的构成要素 The FSM can change from one state to another in response to some external inputs; the change from one state to another is called a transition. An FSM is defined by a list of its states, its initial state, and the conditions for each transition.
有限状态机由状态集合, 初始状态, 状态转移条件定义。
Java实现 根据FSM定义，可以抽象出Java的3种数据类型：
状态(State) 事件(Event)
事件触发状态转移，是状态机的输入。
上下文(Context)
上下文，可以包含各种Condition。
例子：当前状态A，此时输入事件E，如果满足条件C，会导致状态A转换到状态B。这种情况下，A,B是State，E是Event，C是Context下的Condition。
具体代码 状态机运行
public State run() { for (State s = initState; s !</description></item><item><title>JMX学习笔记</title><link>https://blog.yuantops.com/tech/jmx-overview/</link><pubDate>Sat, 22 Jul 2017 18:26:25 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/jmx-overview/</guid><description>JMX，全称Java Management Extensions，借用贾宝玉的一句话描述它：「这个妹妹，我曾见过的。」
见过却不熟悉，它在我心中是Java规范中比较冷门的一个角落。
几次看到Java的招聘JD要求对JMX的理解，所以，在Oracle官网翻到教程，跟着学习学习。
Oracle教程地址 Java Management Extensions(JMX): Table of Contents
这份文档讲的内容很基础，介绍了JMX的整体架构、用处、基础组件，以及给出了带代码的简单演示。
JMX用来做什么？ JMX是Java 标准规范的一部分，可以用来 监控 和 管理 JVM中运行时的资源。除了监控运行时占用的CPU、内核、线程资源，JMX还可以让你直接invoke 方法、修改对象属性（有点暴力了吧。。）。
- JDK中自带的jconsole工具，利用的就是JMX。
JMX可以将管理接口暴露成HTTP调用，这样，通过ip和端口号可以远程监控、管理服务器上的JVM。
- 远程调试需要打开服务器上打开某个端口，利用的也是JMX。
- Tomcat有个HTTP 的管理页面，用的也是JMX。
JMX怎么用 监控JVM
JVM自带支持JMX，开箱即用(out-of-box)。意味着，不需要额外操作就可以用jconsole之类的命令监控JVM。
监控Applicaiton
Application的实现得满足JMX标准。JMX标准是什么，见下文。
JMX标准 MBeans
JMX将它管理的对象称为MBean。换言之，要使用JMX，就得把要管理的资源封装成MBeans。
JMX定义了几类MBeans，就标准MBeans(Standard MBeans)而言，它是这么定义的：后缀为MBean的interface(例如HelloMBean), 以及除去MBean后缀的实现MBean的实现类(这里就是Hello)。
JMX Agent
JMX Agent又称为JMX Server，用来管理MBeans。
关键的代码类似：
MBeanServer mbs = ManagementFactory.getPlatformMBeanServer(); ObjectName name = new ObjectName(&amp;quot;com.example:type=Hello&amp;quot;); Hello mbean = new Hello(); mbs.registerMBean(mbean, name); JMX Connector</description></item><item><title>申请Google Voice号码以及帐号充值小记</title><link>https://blog.yuantops.com/tech/apply-gv-no-and-purchase-credit/</link><pubDate>Fri, 21 Jul 2017 22:30:53 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/apply-gv-no-and-purchase-credit/</guid><description>现在，各种网站窥探用户隐私时越来越理直气壮：注册帐号，非得验证手机号不可。
（当然，他们往往打着《网络安全法》实施的旗号。）
在知乎上看完网友写的在国内拥有一个美国电话号码的必要性，我立刻决定，自己也要来一个美国号码。
下面是我艰辛的折腾记录。
Google Voice是个不错的选择 用户可以在Google Voice上申请虚拟美国电话号码，可以将短信转发到Google Voice的App (iOS上可以用Hangouts)。同时，资费良心，打给国内每分钟也才1美分。
最最重要的，网上申请GV 号码的教程简直汗牛充栋，有了前人栽树，有什么理由不选它乘凉呢？
[失败] DIY: TextNow + 自己申请 于是，怀着工科生的自信，我开始按这份教程的步骤一步步操作。
我发现，第一个问题就难倒我：我的TextNow死也注册不成功。全程美国IP，但就是点到&amp;rdquo;submit&amp;rdquo; 就报错。
其间尝试过TextNow 的手机app 注册，发现手机版好像不支持在线接听电话。
总之，我被弄得没脾气。然后，我把目光投向了万能的淘宝……
[成功] 淘宝搞定Google Voice帐号 淘宝果然没有让人失望。输入Google Voice关键字，宝贝不要太多。随便选了一家，拍下，然后按客服的指引操作，顺利搞定。
淘宝卖家的做法还和我想的不太一样(原本我以为他们是现场申请的)。他们囤着很多Google 小号，每个小号申请一个Google Voice号码。你下单，他会把GV号码过户到你的Google帐号。过户全程需要美国IP，需要登录新旧两个Google 帐号，所以要么你把自己的帐号密码给卖家操作，要么卖家把他的小号给你操作。我自己操作的。
你问工科生的自尊心么？呵呵，当然扔掉啦！
下载Hangouts iOS App Store中国区 居然 可以下载Hangouts。挂上梯子，点开Hangouts，填刚刚申请到手的号码，此时发送的验证码在Google Voice的网页界面看到。
到此为止，基本就搞定。
给Google Voice充钱 充钱是额外选项，完全可以跳过。充了钱可以打电话，还是充点钱吧。
我用建行的visa卡充的。开始死活不成功，把信用卡的bill address改成*美国地址*后顺利成功。这真是坑，莫名其妙的问题，误打误撞解了。
讲真，看到付款邮件的那一刻，眼角有泪划过。</description></item><item><title>Emacs阅读C/C&#43;&#43;代码——生成TAGS文件</title><link>https://blog.yuantops.com/tech/emacs-create-etags/</link><pubDate>Wed, 19 Jul 2017 21:35:16 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/emacs-create-etags/</guid><description> 生成TAGS文件
$ find . -iname &amp;quot;*.[chCHS]&amp;quot; | etags - Emacs 导入TAGS文件
在emacs中，M-x visit-tags-table，选择刚刚生成的TAG文件。
命令：
跳转到光标所在词对应的标签：M-.
回退到上个位置：M-*</description></item><item><title>mkfs 报invalid block count错误</title><link>https://blog.yuantops.com/tech/mkfs-t-not-supported/</link><pubDate>Tue, 27 Jun 2017 10:34:04 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/mkfs-t-not-supported/</guid><description> 问题 在rh 5u7 上用mkfs 创建文件系统，命令
$ mkfs -q -t ext3 -L disk0 /dev/sdb1 居然报错：
……invalid blocks count…… 排查 仔细阅读man mkfs使用文档，是这样写的，没发现哪里用得不对。
mkfs [-V] [-t fstype] [fs-options] filesys [blocks] Google，发现是mkfs 解析参数发生了错误。
原因很简单，mkfs 其实是mkfs.type 的快捷方式。5u 的mkfs 版本过低，不支持-t参数，所以阴差阳错把最后的参数/dev/sdb1 当作了[blocks]。
解法 安装e4fsprogs，这是操作ext4 的工具包。官方文档在此。
改用mkfs.ext4：
$ mkfs.ext4 -q -t ext3 -L disk0 /dev/sdb1</description></item><item><title>JVM 和Java GC 笔记</title><link>https://blog.yuantops.com/tech/jvm-gc-note-1/</link><pubDate>Wed, 21 Jun 2017 23:32:37 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/jvm-gc-note-1/</guid><description>学习材料 讲义地址： http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/gc01/index.html
Youtube 视频地址： Video The JVM and Java Garbage Collection Java &amp;amp; JVM概述 Garbage Collection is automatic. Java source code is compiled into byte code. Byte code is stored in .class files .class files are loaded into a Java Virtual Machine(JVM) and executed. A seperated JVM is created for each Java application. (备注：！每个Java程序都对应着一个单独的JVM) GC 的职责 为新对象分配memory 确保被引用的对象留在memory Ensuring that any referenced objects(live objects) remain in memory 回收死掉的对象占用的memory Recovering memory used by objects that no longer reachable(dead objects) GC的stages step 1.</description></item><item><title>放弃Jekyll，拥抱Hugo</title><link>https://blog.yuantops.com/tech/transfer-from-jekyll-to-hugo/</link><pubDate>Sat, 06 May 2017 14:03:44 +0800</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/transfer-from-jekyll-to-hugo/</guid><description>大约半年前，我更换了自己的工作电脑。装完系统后，开始装各种常用程序。
一切都是那么美好，直到我开始尝试装Jekyll。各种依赖下不下来，或者版本对不上。前者要问候GFW，后者就是Ruby自己的锅了。我，一个Ruby盲，多次被毫不留情的依赖版本问题整崩溃。哪怕一次次长夜痛哭，最终也没有成功。
直到有一天，我看到小巧精炼的Hugo。
Hugo 是用Golang 写的静态网站生成器，只有一个二进制命令，开箱即用。而且，一个命令既可以生成静态文件，又可以直接开http server。所以，那些乱七八糟的gem 包， screw you!
在将Jekyll迁移到Hugo的过程中，需要重新梳理一下文章的组织结构。不过这些都是小case。
我的博客托管在Github Pages。Github本身支持Jekyll引擎，以前直接把markdown文件 push上去就可以，Github会自动帮忙渲染源文件。但Github不支持Hugo的文件布局，所以博客内容要先在本地生成html，再push到github。
我的Github项目地址在这里。hugo分支存放源文件，gh-pages存放编译好的html。
最后，再次赞美go， 赞美Hugo!</description></item><item><title>写一套简易的视频点播系统——API Server</title><link>https://blog.yuantops.com/tech/write-your-own-vod-system-api/</link><pubDate>Wed, 20 Apr 2016 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/write-your-own-vod-system-api/</guid><description>目录 1. 前言 2. 工程代码结构 3. 数据加载流程 前言 作为一个视频点播系统的后台，应该为客户端(见 《写一套简易的视频点播系统&amp;#x2013;Android视频播放器》) 提供合理良好的API接口。同样，这里我们完成了最简单最基本的功能: 基于Spring MVC结构，当有http请求到来时，从MySQL数据库获取数据，返回json格式的数据。
工程代码结构 如下所示(省略了一些文件):
. ├── main/ │ ├── java/ │ │ └── com/ │ │ └── yuantops/ │ │ ├── exception/ //Exception包 │ │ ├── tv/ │ │ │ ├── bean/ //Video对象，对应数据库中数据模型 │ │ │ ├── controller/ //Spring MVC中的C │ │ │ ├── dao/ //数据库增删改查 │ │ │ ├── impl/ //service接口实现 │ │ │ └── service/ //service接口 │ │ └── utils/ //工具类 │ ├── resources/ │ │ ├── application-root-context.</description></item><item><title>写一套简易的视频点播系统——Android视频播放器</title><link>https://blog.yuantops.com/tech/write-your-own-vod-system-android/</link><pubDate>Tue, 19 Apr 2016 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/write-your-own-vod-system-android/</guid><description> 作为一个视频点播系统的客户端，播放视频是最基本的功能。本着最精简最偷懒的原则，这个客户端实现的功能包括:
列表显示服务器上的直播视频、点播视频
点击列表条目，播放视频
工程代码结构 客户端用Android Studio开发，整个项目的结构按gradle风格组织，代码路径是TopsTVPlayer/app/src/main/java。
. └── com └── yuantops └── tvplayer ├── adapter 加载list的Adapter ├── player 播放器组件 ├── ui Fragment和Activity显示界面 └── util 工具类 在player/包下，为直播视频和点播视频分别建立了一个类，因为Android原生的MediaPlayer组件对RTSP协议的直播流支持不全面，所以用原生的MediaPlayer播放点播视频(http)，用Vitamio提供的MediaPlayer播放直播视频(rtsp)。
数据加载流程 所有与网络的数据交流方法都封装在util/VolleySingleton.java文件中，使用了Volley这个优秀的开源http包。
app启动时，首先加载WebAPIServerActivity.java界面，填写web服务器(提供api接口的服务器，不是多媒体服务器)的Base URL。点击确认按钮，会跳转到MainActivity。 MainActivity包含两个Fragment。在Fragment被加载时，会调用VolleySingleton.java里的方法从web服务器上获取json格式的视频列表数据。数据下载完成后，会以list的形式显示出来。 点击listView中的item，会跳转到VideoPlayActivity，初始化对应的直播/点播MediaPlayer。MediaPlayer组件根据视频的URL，从视频服务器获取数据，开始播放。 引用的库 ActionbarSherlock Vitamio SDK Android Volley</description></item><item><title>写一套简易的视频点播系统</title><link>https://blog.yuantops.com/tech/write-your-own-vod-system/</link><pubDate>Sat, 09 Apr 2016 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/write-your-own-vod-system/</guid><description>最初实习时，断断续续写Android代码，实现过用Helix架设流媒体服务器、手机播放流媒体视频的功能。后来一份实习，接触到Spring＋MyBatis框架，见识了它们在处理http请求和数据库连接上的便捷。这几天有些时间，想到可以将它们两者糅合到一起，实现一个完整的视频点播系统，既包括服务器(流媒体服务器，数据库，http服务器)，又包括客户端(Android)。虽然简陋，但工作起来毫无问题。
整个工程运行起来的效果:
打开手机App，填写http服务器提供的api root URL，出现两个列表: 点播视频列表和直播列表。点击列表条目，开始播放视频。
通过手动添加视频文件、修改数据库记录，可以更新视频列表。
这样一个小系统，代码部分包括:
http服务器: 暴露api给访问者，返回json数据。使用了Spring＋MyBatis框架，用Apache Tomcat做Web服务的容器。
Android客户端: 访问http服务器获取数据，并播放流媒体服务器推送的流媒体。
除了写代码，还有一部分配置操作，主要是流媒体服务器Helix。
写代码和配置服务器软件的工作量，加起来与计算机专业本科的课程设计工作量相当。这些工作将由三篇文章分别介绍。</description></item><item><title>用Android 手机玩延时摄影</title><link>https://blog.yuantops.com/tech/timelapse-photography-diy-android/</link><pubDate>Fri, 11 Dec 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/timelapse-photography-diy-android/</guid><description>延时摄影是一种很精妙细微的展现形式，时间被压缩后有流动的美。每隔固定时间按一次快门，再将照片按某个帧率连续起来，就生成一段流畅的视频。摄影发烧友一般用单反拍照，用快门线控制拍照的周期。鉴于单反不是人人都有（譬如我就没有。。），这里分享一个经济实用的点子，用安卓和电脑来DIY延时摄影。
思路 Android 系统开放了一些接口，Debug模式下电脑可以通过Android SDK提供的adb 命令调用它们，模拟启动相机、聚焦、拍照动作，并将照片保存到电脑硬盘。将这一连串操作用脚本记录下来，并设置linux定时任务，周期执行。最后，通过ffmpeg 或者其他视频编辑软件将照片变成视频/gif。
器材 一部安卓手机 + 一台电脑(假设为Linux) + 一根USB线
拍摄主题 玫瑰花绽放
做法 我手头有一部大概一年前买的红米，测试了下拍照效果，虽然比不上正在用的5c但也相当凑和。笔记本刚刚重装了个系统(Arch)，在官网上下好了新鲜热乎的Android SDK。
用USB线将手机连到笔记本，打开手机的Debug模式。另外，推荐将手机设置为Debug模式下屏幕常亮。用Android SDK的platform-tools目录下的adb命令检查是否顺利连接了手机。我在自己的机器上折腾红米的挂载还颇费了一点力气，具体操作可以google之，此处不赘述。
用脚本调用adb命令，实现启动相机、聚焦、拍照、保存照片到电脑、删除手机上的照片等一连串操作。将照片从手机上删除是考虑到手机SD的容量有限。Shell脚本实现起来最简单。这里不得不赞叹adb的强大，不仅可以用&amp;rdquo;adb shell&amp;rdquo;像普通linux系统一样操作Android设备，还可以向设备发送按键动作、模拟触屏动作等。如何发送Keyevent，如何捕捉(capture)、记录(record)、发送屏幕触摸动作，可以Google之，此处不赘述。
将脚本作为系统的定时任务执行。Linux下用crontab可以非常方便地实现。如何设置定时任务的时间间隔，需要做一点小数学题，用拍摄对象的总耗时与视频的帧率算出来，具体参考博客。
做完前期的技术准备后，该拍摄主角登场了。我选择的拍摄主题是“鲜花绽放”，所谓一支浓艳露凝香，在我心中玫瑰是坠吼不过的了。在花店用3人民币买了一朵含苞待放的玫瑰花骨朵儿。给它粘个背景，插在一个透明酸奶罐子中，架好灯光（淘宝买的USB LED灯）。固定好手机，缚得牢牢的，不要让它晃动。
静静地让程序跑，跑，跑。。。。（宿舍晚上会熄灯，这是比较麻烦的，暂时我还没想到解决办法。不过幸亏玫瑰花儿开得快，白天就很饱满了。）
时间大概过去了五个小时。。。
好了，花儿开好了。
打开电脑上存放照片的目录，用ffmpeg或者别的视频编辑软件，将它们合成视频。（我这里为了方便合成的是gif。）
Github例子 我的Shell脚本见这个项目。
最后是gif效果图，考虑到博客容量我降低了图片尺寸和质量。</description></item><item><title>C语言堆与栈的区别</title><link>https://blog.yuantops.com/tech/c-heap-vs-stack-memory/</link><pubDate>Thu, 17 Sep 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/c-heap-vs-stack-memory/</guid><description>C语言中动态区域由Stack和Heap两部分组成。简单说来，Stack由编译器自动分配释放，存放函数的参数值、局部变量等值，底层的数据结构是LIFO的栈。Heap由程序员分配释放，如果一不小心忘记了释放申请的内存，可能引起内存泄漏。Heap基于的数据结构比较复杂。
区别 申请方式 Stack由系统自动分配，存放局部变量等。 Heap由程序员调用malloc, realloc, calloc申请，并用free释放。
申请效率 Stack由系统自动分配，速度快，程序员无法控制。
Heap由程序员申请、释放，容易产生碎片，效率低于Stack。
空间大小 Stack在Linux内存区域中由高地值向低地址生长，大小固定，地址是连续的。当栈的剩余控件不足时，会提示Overflow。
Heap在内存区域中由低地址向高地址生长，是不连续的内存区域。堆的大小受制于系统有效的虚拟内存。
分配方式 Stack是连续的。只要栈的空间大于所申请的空间，系统将为程序分配空间，否则会报Overflow。
Heap收到程序申请时，操作系统有一个记录空闲内存地址的链表，会遍历该链表，寻找第一个空间大于所申请空间的堆节点，然后将该节点从空闲链表中删除，并将该节点的空间分配给程序。另外，如果找到的堆节点大小不一定正好等于申请的大小，系统会自动将多余的部分重新放入空闲链表中。反复的申请/释放，势必会生成大量的内存空间碎片，使程序效率降低。
存储内容 Stack：当函数调用时，第一个进栈的是主函数中下一条语句的地址，然后是函数的各个参数，参数是从右往左入栈的，然后是函数中的局部变量。静态变量不入栈。
当本次函数调用结束后，局部变量先出栈，然后是参数，最后是栈顶指针所指向的、主函数中的下一条指令，程序由该点继续执行。
Heap：往往会在堆的头部用一个字节存放堆的大小，以利于free函数的释放。</description></item><item><title>Java堆内存与栈内存的区别</title><link>https://blog.yuantops.com/tech/java-heap-vs-stack-memory/</link><pubDate>Thu, 17 Sep 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/java-heap-vs-stack-memory/</guid><description> Java中提供&amp;rdquo;栈&amp;rdquo;这种数据结构的实现，java.util.Stack。但此处我们所讨论的不是数据结构，而是JVM内存中的堆与栈，Java Runtime中存放数据的地方。
JVM中的堆 Java Runtime使用Heap为Object分配内存。所有的对象，无论是何时何地创建的，都保存在Heap中。垃圾回收(Garbage Collection)在Heap上运行，释放不被引用的Object。Heap中生存的Object能在程序的任何地方被引用。
JVM中的栈 Stack memory是为执行的thread分配的，包含一些生存时间短的值和指向Heap中对象的引用。Stack Memory总是LIFO的。当调用一个Method时，Stack Memory会为它分配一块区域，用来存储本地的primitive value和对Object的引用。一旦这个method结束，这块区域将变得不可用，下一次Method调用时又可以使用它。
相比Heap，Stack要小得多。
区别 存储内容：栈存放局部变量以及引用，堆存放所有对象。
被谁占有：堆被整个程序共享，栈中的对象被所有线程可见；栈属于单个线程，存储的变量只在其所属的线程中可见。
空间管理：Stack内存满足LIFO，但Heap就复杂多了。Heap被分为Young Generation, Old Generation, Permanent Generation，在它基础上会运行垃圾回收机制。 生存时间：Stack Memory伴随调用它的Method存在、消失，而Heap Memory从程序的开始一直存活到终止。
体积大小：Stack Memory体积远大于Heap Memory。由于Stack用LIFO调度，它的访问速度也快得多。可以用-Xms或者-Xmx定义Heap的初始大小，用-Xss定义Stack的初始大小。
异常错误：当Stack满了，Java Runtime会抛出java.lang.StackOverFlowError。当Heap满了，会抛出java.lang.OutOfMemoryError: Java Heap Space Error。</description></item><item><title>LaTeX安装以及生成pdf时字体找不到的处理办法</title><link>https://blog.yuantops.com/tech/latex-installation-and-basics/</link><pubDate>Tue, 08 Sep 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/latex-installation-and-basics/</guid><description>安装软件包 $ sudo apt-get install texlive texlive-science
编译命令 tex编译: $ latex hello.tex
输出为pdf: $ dvipdf hello.dvi
输出为ps: $ dvips hello.dvi
如果生成pdf时报&amp;rdquo;Font Helvetica is not in the mapping file&amp;rdquo; 类似错误 出现这种情况，原因可能有几种，最可能的是系统没有安装这个字体。具体解释见这篇文章。
处理办法：安装ghostscript命令，用它自带的命令，先将pdf转成ps，再以强制嵌入字体的方式将ps回转为pdf。详细的步骤见这篇文章。
具体命令:
1. covert to postscript:
$ pdftops origin.pdf origin.ps
2. reconvert to pdf, but enforce font embedding:
$ ps2pdf14 -dPDFSETTINGS=/prepress -dEmbedAllFonts=true origin.ps new.pdf
3. verify format of new file:
$ pdffonts new.pdf</description></item><item><title>Android SurfaceView双缓存机制与闪屏现象分析</title><link>https://blog.yuantops.com/tech/surfaceview-dual-cache/</link><pubDate>Sun, 26 Jul 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/surfaceview-dual-cache/</guid><description>##理解SurfaceView
SurfaceView是View的子类，所以View有的特点它都有。但它有特殊之处：它引入了缓存机制，优化了内容刷新的过程，使UI Thread不至于崩溃。更新它的内容，我们要用到与之关联的SurfaceHolder。
比较特殊的在于SurfaceView的“双缓存”(Double-buffer)机制。更新SurfaceView的常见流程是&amp;rdquo;lockCanvas-drawCanvas-unlockCanvasAndPost&amp;rdquo;, 如果你遇到SurfaceView闪烁的情况，像鬼片里电视机的那种闪法，那十之八九是栽倒在双缓存的坑里了。Google告诉了我这个问题的答案，希望你能用上。
##双缓存(Double-buffer)与黑屏闪烁
以下内容来自邮件列表的讨论，我对它们进行一点梳理。
每个SurfaceView 对象有两个独立的graphic buffer，官方SDK将它们称作&amp;rdquo;front buffer&amp;rdquo;和&amp;rdquo;back buffer&amp;rdquo;。
常规的&amp;rdquo;double-buffer&amp;rdquo;会这么做：每一帧的数据都被绘制到back buffer，然后back buffer的内容被持续翻转(flip)到front buffer；屏幕一直显示front buffer。但Android SurfaceView的&amp;rdquo;double-buffer&amp;rdquo;却是这么做的：在buffer A里绘制内容，然后让屏幕显示buffer A; 下一个循环，在buffer B里绘制内容，然后让屏幕显示buffer B; 如此往复。于是，屏幕上显示的内容依次来自buffer A, B, A, B,&amp;hellip;.这样看来，两个buffer其实没有主从的分别，与其称之为&amp;rdquo;front buffer&amp;rdquo;&amp;ldquo;back buffer&amp;rdquo;，毋宁称之为&amp;rdquo;buffer A&amp;rdquo;&amp;ldquo;buffer B&amp;rdquo;。
Android中&amp;rdquo;double-buffer&amp;rdquo;的实现机制，可以很好地解释闪屏现象。在第一个&amp;rdquo;lockCanvas-drawCanvas-unlockCanvasAndPost&amp;rdquo;循环中，更新的是buffer A的内容；到下一个&amp;rdquo;lockCanvas-drawCanvas-unlockCanvasAndPost&amp;rdquo;循环中，更新的是buffer B的内容。如果buffer A与buffer B中某个buffer内容为空，当屏幕轮流显示它们时，就会出现画面黑屏闪烁现象。
##解决方法 出现黑屏是因为buffer A与buffer B中一者内容为空，而且为空的一方还被post到了屏幕。于是有两种解决思路：
不让空buffer出现：每次向一个buffer写完内容并post之后，顺便用这个buffer的内容填充另一个buffer。这样能保证两个buffer的内容是同步的，缺点是做了无用功，耗费性能。
不post空buffer到屏幕：当准备更新内容时，先判断内容是否为空，只有非空时才启动&amp;rdquo;lockCanvas-drawCanvas-unlockCanvasAndPost&amp;rdquo;这个流程。</description></item><item><title>用Helix Server建立点播流/直播流的方法</title><link>https://blog.yuantops.com/tech/helix-server-streaming-guide/</link><pubDate>Thu, 23 Jul 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/helix-server-streaming-guide/</guid><description>视频文件预处理 Helix Server支持的视频格式很多，我只使用过MP4格式，其余的格式请自行探索。
一个MP4格式的视频文件要想被Helix流化，必须具有符合要求的头部信息。mp4box这个小命令正是用来做这件事的，它是开源软件GPAC内提供的命令。先安装GPAC(https://gpac.wp.mines-telecom.fr/mp4box/)， 后在安装目录下找到MP4BOX.exe。如何调用命令不赘言。它的使用格式是：
mp4box mymovie.mp4 -hint
在安装Helix Server前，将所有的视频文件都用这条命令处理一遍。
安装 Helix Server是收费的，但在官网能申请到一个试用版license，免费使用一段时间。当然，如果你在网上找到了破解版，请在使用时自觉忏悔。
安装过程不多说，只是要注意记忆所设的帐号和密码。安装完成后，在桌面会生成两个图标：一个指向web控制台，还有一个是启动Helix的快捷方式。我们双击web控制台的图标，输入帐号和密码，进入Web Console。
参数配置 进入Web Console后，左侧是一栏设置菜单，右侧是对应菜单条目的详情。在Web Console上我们能完成点播流的所有配置,以及直播流的必要配置。
添加服务器的IP地址
左侧：&amp;rdquo;服务器设置&amp;rdquo;-&amp;ldquo;IP绑定&amp;rdquo;
右侧：点击小加号，输入服务器的IP地址。
配置流服务的端口号
Helix 的点播支持Http协议、RTSP协议，直播支持RTSP协议。Helix为这些协议分配了默认的端口号，如果有需要的话我们可以修改它们。
左侧：&amp;rdquo;服务器设置&amp;rdquo;-&amp;ldquo;端口&amp;rdquo;
右侧：修改&amp;rdquo;RTSP端口&amp;rdquo;，&amp;rdquo;HTTP端口&amp;rdquo;。
添加视频加载点
左侧：&amp;rdquo;服务器设置&amp;rdquo;-&amp;ldquo;配置加载点&amp;rdquo;
右侧：点击&amp;rdquo;加载点描述&amp;rdquo;右边的小加号
&amp;ldquo;编辑描述&amp;rdquo;随便给这个配置取一个描述性的名字；
&amp;ldquo;加载点&amp;rdquo;设置视频目录的加载点（它将作为视频流URL的一部分出现），输入内容形如&amp;rdquo;/NGB/&amp;ldquo;（注意有两个左斜杠）；
&amp;ldquo;基于路径&amp;rdquo;输入视频文件所在目录的绝对路径，形如&amp;rdquo;E:\Videos&amp;rdquo;。
将加载点添加到HTTP 分发目录
左侧：&amp;rdquo;服务器设置&amp;rdquo;-&amp;ldquo;HTTP分发&amp;rdquo;
右侧：点击&amp;rdquo;路径&amp;rdquo;右边的小加号，在&amp;rdquo;编辑路径&amp;rdquo;中填入上面设置的视频加载点，形如&amp;rdquo;/NGB&amp;rdquo;(注意此处只有一个左斜杠)。
将MP4格式加到HTTP协议支持的MIME类型列表
左侧：&amp;rdquo;服务器设置&amp;rdquo;-&amp;ldquo;MIME类型&amp;rdquo;
右侧：点击&amp;rdquo;MIME类型&amp;rdquo;右边的小加号
&amp;ldquo;编辑MIME类型&amp;rdquo;填入&amp;rdquo;video/mp4&amp;rdquo;
&amp;ldquo;扩展名&amp;rdquo;填入&amp;rdquo;mp4&amp;rdquo;
测试配置是否成功
假设视频文件目录有文件&amp;rdquo;E:\Videos\akame.mp4&amp;rdquo;,视频目录挂载点为&amp;rdquo;/NGB/&amp;ldquo;,配置的Http协议端口为80，Rtsp协议端口为554。在PC上打开一个能播放网络媒体流的视频播放器（推荐VLC），输入下面的URL播放视频：
http://192.168.1.100:80/NGB/akame.mp4
rtsp://192.168.1.100:554/NGB/akame.mp4
点播流的创建到此结束了。完成上述步骤后，下面再来介绍如何用Helix 提供的小命令，由视频文件生成模拟直播流。
生成模拟直播流 准备命令</description></item><item><title>Ali面试记录</title><link>https://blog.yuantops.com/tech/interview-ali-record-1/</link><pubDate>Thu, 19 Mar 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/interview-ali-record-1/</guid><description>记录： 1. 以支付宝的输入密码界面为例。当支付宝再次回到前台时，有时会进入输手势密码的界面。请问你的实现思路？
面试官的解答：编写一个BaseActivity继承Activity，然后App中所有的Activity都继承BaseActivity。在BaseActivity中设置计时器，重写BaseActivity的onStop()和onStart()方法&amp;hellip;.
百度、腾讯等旗下有多款App，这些App有的在后台共享SDK数据。请问其中原理？
IPC调用。
Android中APP是单例还是多例？
判断一个Activity是不是位于栈顶。
Java中run()和start()区别
Java中lock()和Syncronized()区别
在按下Back键时，如何自定义返回到哪个Activity？</description></item><item><title>Git重新应用gitignore文件规则</title><link>https://blog.yuantops.com/tech/refresh-gitigore/</link><pubDate>Tue, 17 Mar 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/refresh-gitigore/</guid><description>这个问题参见StackOverflow，记录在下面：
保险起见，先对当前Repo提交一个commit，以防丢失数据；
然后，
git rm -r &amp;ndash;cached .
git add .
git commit -m &amp;ldquo;fixed untracked files&amp;rdquo;</description></item><item><title>REST基础概念笔记</title><link>https://blog.yuantops.com/tech/rest-basics/</link><pubDate>Thu, 29 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/rest-basics/</guid><description>Representational State Transfer(REST)
REST is an architecture style or design pattern used as a set of guidelines for creating web services which allow anything connected to a network (web servers, private intranets, smartphones, fitness bands, banking systems, traffic cameras, televisions etc.) to communicate with one another via a shared common communications protocol known as Hypertext Transfer Protocol (HTTP). &amp;ndash;REST Wikipedia
REST是一种架构风格，设计模式，因此没有一本语法书规定REST应该这样实现，应该那样实现。它不是一种标准。它是一种风格，具有指导意义，凡是遵循这种风格的设计，都可以称之为&amp;rdquo;RESTful&amp;rdquo;。
REST的常见应用场景是Web服务。在RESTful API的实际实现中，往往遵循一些*约定的*规则：
基于URI，例如http://example.com/resources/
传输的数据格式是JSON。虽然理论上数据格式可以是任意一种(XML,ATOM等)，但往往大家都用JSON。
使用标准HTTP方法，即GET, PUT, POST, DELETE四个动词。</description></item><item><title>视频格式学习笔记</title><link>https://blog.yuantops.com/tech/video-format-and-container-study/</link><pubDate>Wed, 28 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/video-format-and-container-study/</guid><description> 在生活语境里所说的“视频格式”，在学术上有两个概念与之对应：Container format (封装格式)和Codec (暂且译为“编解码格式”)。
Container format (封装格式) Container format 描述了视频文件的结构。正如它的字面含义所说，它是对一个“容器”的规范。一个视频文件往往会包含图像和音频，还有一些配置信息(如图像和音频的关联，如何解码它们等)：这些内容需要按照一定的规则组织、存储起来，Container format就是这些规则。
如果一个视频文件是以某个Container format封装起来的，那么它的后缀名一般会体现出来。所以，后缀名只是形式，只是为了便于识别(例如，windows系统会根据文件的后缀名决定以什么程序打开它)，不代表实质性的内容。
附录(一)是常见的视频封装格式和后缀的对应表。
Codec (编解码格式)
Codec是一种压缩标准。而文件的压缩/还原是通过编/解码实现的，所以Codec也可理解成编/解码标准。要知道，未经过处理的原始视频和音频文件十分巨大，不好存储、传输。为了节省磁盘空间和网络带宽，原始的视频和音频文件都会通过编码压缩体积，然后需要播放时再通过逆向过程解码还原。Codec就是规定编/解码实现细节(数字存储空间、帧速率、比特率、分辨率等)的标准，不同的标准对于压缩的质量和效率有影响。
世界上制定这套标准的有两大阵营：ITU-T VCEG(Visual Coding Experts Group，国际电联旗下的标准化组织)和MPEG(Moving Picture Experts Group, ISO旗下的组织)。MPEG系列标准是MPEG制定的，H.26x系列标准是ITU-T制定的。这两套标准的更进一步介绍可以参见附录(二)。
Container format 和Codec 有关系吗？
不妨将视频文件看作容器(Container)，那么这个容器里盛放的就是遵循某种Codec的内容(Content)。一个容器里应该能放下视频、音频、数据信息，即使它们遵循的Codec不相同。例如，QuickTime File Format (.MOV)支持几乎所有的Codec，MPEG(.MP4)也支持相当广的Codec。所以，单从视频文件的格式是无法获知它的质量细节的，这些细节取决与采用的Codec。比较专业的说法是，“给我一个H.264 Quicktime文件(.mov)”。
为何还是有点迷糊？
以上的解释是从学术角度出发的。只要分清了这些术语，那么在学术讨论时不会有含糊。但现实生活中人们不会一丝不苟地区分“Container format ”“Codec”，往往只会说“这是一个mov文件”。这是日常用语与学术术语混用造成的理解上的混乱。
另外，Container format和Codec的命名也有让清醒的人摸不清头脑。例如，“MPEG-4”既是“Container format ”，也是“Codec”，这也让混乱的名词世界更糟糕。
参考 https://library.rice.edu/services/dmc/guides/video/VideoFormatsGuide.pdf https://app.zencoder.com/docs/faq/codecs-and-formats 附录一 常见的视频封装格式和后缀的对应表</description></item><item><title>Linux确定监听某个端口的进程</title><link>https://blog.yuantops.com/tech/find-out-process-listening-on-a-port/</link><pubDate>Thu, 22 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/find-out-process-listening-on-a-port/</guid><description>比较常见的命令有:
netstat
lsof
ps /proc/$pid
netstat # netstat -tuapn 参数解释:
-t tcp协议 -u udp协议 -a 显示listening和non-listening端口 -p 显示process ID -n 显示数字IP，而不是字符形式的hostname 可以用grep命令对上条命令的输出进行过滤，显示某条端口的信息。
lsof # lsof -i :4000 lsof列出机器上打开的所有文件。这条命令输出端口4000被占用的情况。它的输出形如
COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME
ruby-mri 10482 yyuan 11u IPv4 252906 0t0 TCP localhost:terabase (LISTEN)
可以看到进程号10482的进程占用了TCP端口4000。
ps # ps aux 参数解释: -a 显示所有用户的进程
-u 显示进程的user/owner
-x 也显示不与终端关联的进程
同样地，也可以用grep命令对上条命令的输出进行过滤，显示某条端口的信息。
/proc/$pid 下面是该目录下，各个文件的作用:</description></item><item><title>Eclipse中添加Tomcat插件</title><link>https://blog.yuantops.com/tech/install-tomcat-plugin-in-eclipse/</link><pubDate>Wed, 21 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/install-tomcat-plugin-in-eclipse/</guid><description>##安装Tomcat 下载链接:Tomcat7
下载tar.gz包到本地，譬如到/home/yuan/Downloads目录
通过tar -zxf **.**.tar.gz命令解压tar.gz包，将解压出来的文件夹转移到你希望保存的目的地(譬如说/home/yuan/tomcat7)
用vi打开~/.bashrc文件，在末尾添加如下内容:
alias tomcat=&amp;lsquo;bash ~/tomcat7/bin/startup.sh&amp;rsquo;
export CATALINA_HOME=/home/tomcat7
export JRE_HOME=/usr/lib/jvm/java-7-openjdk-i386/jre
其中，JRE_HOME是本机的JRE环境所在目录，需要根据系统的安装情况而定。
保存退出
现在，重新打开终端，运行tomcat可以启动Tomcat服务
##在Eclipse中添加Tomcat插件 下载链接: TomcatPluginV33.zip
下载压缩包，将解压后的目录复制到Eclipse安装目录下的plugins/目录。启动Eclipse，可以在状态栏中看到三个有小猫的图标。
菜单栏，&amp;rdquo;Window&amp;rdquo;-&amp;ldquo;Preferences&amp;rdquo;-&amp;ldquo;Tomcat&amp;rdquo;,将Tomcat version和Tomcat home改为对应值。
单击小猫图标，即可启动Tomcat。在浏览器中输入http://127.0.0.1:8080能看到欢迎页。
##在Eclipse中新建一个Tomcat项目 - &amp;ldquo;File&amp;rdquo;-&amp;ldquo;New&amp;rdquo;-&amp;ldquo;Project&amp;hellip;&amp;rdquo;-&amp;ldquo;Java&amp;rdquo;-&amp;ldquo;Tomcat Project&amp;rdquo;,新建一个Tomcat工程。
- 添加源码在&amp;rdquo;WEB-INF/src&amp;rdquo;目录下。
- 不要忘记在&amp;rdquo;WEB-INF&amp;rdquo;目录下添加web.xml文件。</description></item><item><title>IPv4协议保留的私有IP段</title><link>https://blog.yuantops.com/tech/ipv4-private-address-space/</link><pubDate>Tue, 20 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ipv4-private-address-space/</guid><description>这三个保留IP地址段是:
10.0.0.0/8 IP addresses: 10.0.0.0 &amp;ndash; 10.255.255.255
172.16.0.0/12 IP addresses: 172.16.0.0 &amp;ndash; 172.31.255.255
192.168.0.0/16 IP addresses: 192.168.0.0 – 192.168.255.255
注意，所有以&amp;rdquo;172&amp;rdquo;和&amp;rdquo;192&amp;rdquo;打头的IP中只有部分是保留IP。</description></item><item><title>北邮校园网通过配置IPv6使用Google服务</title><link>https://blog.yuantops.com/tech/config-ipv6-to-bypass-gfw-in-bupt/</link><pubDate>Sat, 17 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/config-ipv6-to-bypass-gfw-in-bupt/</guid><description>前提 首先，本文针对的是北邮校园网。我在北邮学十亲测，机器是Linux Mint。
其次，请确保:
自己的机器支持IPv6。Win7默认安装了IPv6协议，WinXP可能需要自己手动安装。我自己的Linux mint默认安装了IPv6。
自己的网络支持IPv6。包括北邮在内的绝大多数高校校园网都架设了IPv6，通过校园网上网的同学理论上不必担心这点。所以，还在使用校园网的同学们，趁IPv6还没被盯上，珍惜现在吧。
验证方法
打开浏览器，访问IPv6test.com，页面上&amp;rdquo;IPv6 connectivity&amp;rdquo;一项如果显示&amp;rdquo;Supported&amp;rdquo;，说明前提条件满足。或者访问BYR BT，这是只支持IPv6方式访问的站点，如果能访问也说明前提条件满足。
目标 使用谷歌的服务(google search, gmail, google calendar, google scholar, google plus, youtube, etc.)
访问其它支持IPv6的网站: wikipedia, facebook, etc.
除了能部分避开G)(F)(W之外，北邮校园网内通过IPv6通道产生的流量是不计费的，所以，即使从节约流量这一点看也是值得的。
姿势简介 总的来说，这个方法是靠访问网站的IPv6地址。如果要去的网站没有IPv6地址，那就没辙。而让我的电脑知道一个网站的IPv6地址(如果存在的话)，有两个法子:
修改hosts文件
使用IPv6 DNS服务器
当系统准备访问一个站点时，它需要知道目的站点的IP地址。它先会读取hosts文件，看里面是否有* IP-主机名* 的记录。如果有，它会直接按IP地址访问站点。如果hosts文件中没有相应记录，那么它会向系统设置的DNS服务器查询。DNS服务器会返回目的站点的IP地址。
所以，这两个方法可以同时使用。(有关DNS的知识，本文限于篇幅将不做讨论。)
修改hosts文件 这是一份内容随时更新的hosts文件：Hosts 。这份文件属于托管在GitHub上的一个项目，里面除了IPv6地址外还有一小部分由活雷锋搜集的IPv4地址，大家可以参考。
将Hosts文件的文本复制过来，用任意一款文字编辑器打开hosts文件，将内容粘贴进来。
hosts文件在不同操作系统中的位置不同。在Windows下，它的默认路径是:
%SystemRoot%\system32\drivers\etc\hosts
在Linux下，以我的Mint为例，它的路径是:
/etc/hosts
修改它需要系统权限。如果是Linux，记得在前面加上sudo。
改完hosts，就已经能达到我们的目标了，可以使用Google的服务了。当然，我们还可以继续下面一步，来个双保险。
使用IPv6 DNS服务器 支持IPv6 的免费DNS解析服务器很多，在此仅以Google为例。如果使用其它的IPv6 DNS服务器，将下文中的IP地址替换过来就好。
Google提供公共DNS解析服务，能解析IPv6地址。Google DNS服务器在它的IPv6地址上监听IPv6的通道发来的查询请求。如果这个查询求的是IPv6地址，而且地址存在，那么Google服务器会返回结果AAAA记录。
GoogleDNS服务器的IPv6地址是:
2001:4860:4860::8888</description></item><item><title>厘清Java Socket端口问题 -- 服务器的端口是什么</title><link>https://blog.yuantops.com/tech/some-clarification-about-java-socket-port/</link><pubDate>Tue, 13 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/some-clarification-about-java-socket-port/</guid><description>在我之前翻译的Socket是什么一文中，对java中socket建立的流程有描述。在服务器接受客户端socket连接的部分，它这么说道：
如果一切顺利，服务器会接受连接。一旦接受了连接，服务器会得到一个绑定了本地相同端口的新socket，这个socket的另一端被置为客户端的地址和端口。服务器需要一个新的socket,所以它能一边继续在原来的socket监听连接请求，一边处理已建立连接的客户端的需求。
(原文)
If everything goes well, the server accepts the connection. Upon acceptance, the server gets a new socket bound to the same local port and also has its remote endpoint set to the address and port of the client. It needs a new socket so that it can continue to listen to the original socket for connection requests while tending to the needs of the connected client.</description></item><item><title>理解Docker -- Docker Official Docs翻译</title><link>https://blog.yuantops.com/tech/understanding-docker/</link><pubDate>Mon, 12 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/understanding-docker/</guid><description>Docker是什么 Docker是用于开发(develop)、转移(ship)、运行(run)程序(application)的一个开放平台。Docker的设计目的是为了更快地传递程序。在Docker的帮助下，你能将程序与硬件基础(infrastructure)隔离、把硬件基础看作一个可管理的程序。Docker能帮你更快地转移代码、测试代码、部署代码，缩短编写代码与运行代码之间的周期。
Docker将一种轻量级的容器虚拟化平台技术(container virtualization platform)与相应的工作流程和工具结合起来，从而能帮你管理、部署自己的程序。
在核心层面，Docker支持在一个容器(container)中安全(securely)、独立(isolated)地运行几乎任何一种程序。这种独立性、安全性允许你在主机(host)上同时运行多个容器。容器在运行时不需要分配额外负载给监视程序(hypervisor)，它的这种轻量级特性意味着你能更大限度地使用硬件资源。
基于容器虚拟化，Docker提供的工具和平台能帮助你：
将你的程序(和支持的组件)放到Docker容器中
分发(distribute)、转移(ship)这些容器给自己的团队成员，以便他们后续的开发和测试
把这些程序部署到产品环境中，不管你的产品环境位于本地数据中心还是在云中
我能用Docker做什么？ 更快地转移程序
Docker是帮你处理开发周期的绝好工具。Docker能允许开发者在包含你的程序和服务的本地容器上开发，然后它能整合到一个连续的整合、部署工作流程中。
举个例子。开发者在本地编写程序，通过Docker将开发环境与同事共享。当他们的工作完成时，开发者将他们的代码和开发环境推送到一个测试环境上，并且执行任何必要的测试。然后，你能从测试环境将Docker镜像(image)推送到产品，部署代码。
更方便地部署、扩展
Docker基于容器的平台支持高便携性(portable)的工作负载(workload)。Docker容器能运行在开发者的本地机器上、数据中心的物理/虚拟机器上，也能运行在云端。
支持更高密度，运行更多工作负载
Docker是轻量级的，而且很快。与基于监督程序(hypervisor)的虚拟机相比，它提供了可变的、低消耗的替代方案。在高密度(high density)的工作环境中，这一点就显得格外重要，例如：当搭建你自己的云或者Platform-as-a-service服务时。不止如此，当你想尽可能地利用你的资源来做小型/中型的部署时，Docker也同样有用。
Docker的主要组件有哪些？ Docker主要组件有两个：
Docker: 开源的容器虚拟化平台 Docker Hub：Software-as-a-Service平台，用来分享、管理Docker容器
注意：Docker受开源协议Apache 2.0约束
Docker的架构 Docker使用客户端-服务器架构。Docker客户端(client)与Docker守护进程(deamon)通信，后者来完成建立版本(build)、运行(run)、分发(distribute)Docker容器等工作。Docker客户端和守护进程*可以*同时运行在一个系统上；你也可以将Docker客户端连接到一个远程Docker守护进程。Docker客户端和Docker守护进程通过socket或者REST API通信。
Docker守护进程 如上图所示，Docker守护进程运行在一台宿主机器上。用户不直接与守护进程通信，而是通过客户端与之通信。
Docker客户端 Docker客户端，往往是二进制形式的docker程序，是Docker最主要的用户使用接口。它接收来自用户的命令，将它来回地与守护程序进行通信。
在Docker内部 为了理解Docker的内部原理，你需要理解三个组件：
镜像(image)
仓库(registry)
容器(container)
#镜像 镜像是一个只读(read-only)的模板。例如，一个镜像可能包含安装了Apache和你的Web服务器的一个Ubuntu操作系统。镜像是用来创造Docker容器的。通过Docker，你能以简单的方式创建新的镜像、更新现存的镜像，或者下载别人已经创建好了的镜像。Docker镜像是Docker的创建(build)组件。
仓库 仓库保存镜像。它们是你用来上传、下载镜像的私有/公有场所。官方的Docker仓库是Docker Hub，它提供了一个巨大的镜像仓库集以供你使用。你可以自己创建镜像，也可以使用别人事先已经建好了的镜像。Docker仓库是Docker的分发(distribute)组件。
容器 容器与目录类似。容器包含了运行一个程序所需要的所有东西。每个容器都是创建自一个镜像。容器可以被运行、启动、停止、移动、删除。每个容器都是一个隔离、安全的程序平台。Docker容器是Docker的运行(run)组件。
那么，Docker到底如何工作？ 现在，我们已经知道：
你可以创建Docker镜像来保存程序
你可以从Docker镜像中新建Docker容器来运行程序
你可以通过Docker Hub或者自己的私有仓库来分享Docker镜像
下面，让我们看看这些组件是如何协作起来使Docker工作的。</description></item><item><title>Activity的生命周期以及两个Activity跳转时的状态变化</title><link>https://blog.yuantops.com/tech/android-activity-lifecycle-with-two-activites/</link><pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/android-activity-lifecycle-with-two-activites/</guid><description>##Android Activity的生命周期 下面这张图非常清晰地介绍了Activity的生命周期：
##当通过intent跳转时的状态变化 一个Activity的状态有三个：Stopped(存在但看不见)，Paused(部分可见，但无焦点)，Resumed(激活状态，拥有焦点，可以与之交互)。如果将不存在也算作一个状态，那样一共就有四个状态。
这篇文章非常详细地讨论了当通过intent在一个Activity中启动另一个Activity时，它们两个Activity的状态变化过程。
当由MainActivity跳转到ActivityTwo时，下面是方法的调用顺序：
MainActivity: onPause() ActivityTwo: onCreate() ActivityTwo: onStart() ActivityTwo: onResume() MainActivity: onStop() 步骤为：MainActivity失去焦点，转到Paused状态-&amp;gt;ActivityTwo新建但不可见,处于Stopped状态-&amp;gt;ActivityTwo可见，处于Paused状态-&amp;gt;ActivityTwo获得焦点，处于Resumed状态-&amp;gt;MainActivity不可见，处于Stopped状态。
值得注意的是，当ActivityTwo位于前台时，MainActivity并没有被销毁，而是仍保存在内存中。
按下后退键，由ActivityTwo返回MainActivity时，方法的调用顺序为：
ActivityTwo: onPause() MainActivity: onRestart() MainActivity: onStart() MainActivity: onResume() ActivityTwo: onStop() ActivityTwo: onDestroy() 步骤与上一步类似。值得注意之处有二：
其一，MainActivity.onRestart方法先于MainActivity.onStart方法调用。如果Activity不是从无到有新建出来的，那么在onStart方法前都会先调用onRestart方法。
其二，ActivityTwo被销毁了。至于为什么此时ActivityTwo会被销毁，涉及到Task的原理。在这篇文章中有介绍。</description></item><item><title>Android中Context的作用</title><link>https://blog.yuantops.com/tech/use-of-context-in-android/</link><pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/use-of-context-in-android/</guid><description>##官方文档中对Context的介绍 &amp;gt;Interface to global information about an application environment. This is an abstract class whose implementation is provided by the Android system. It allows access to application-specific resources and classes, as well as up-calls for application-level operations such as launching activities, broadcasting and receiving intents, etc.
翻译：
Context是Android应用的全局信息的接口。它是一个虚类，它的实现由Android系统完成。它提供了对某个应用的资源和类的访问权限，也提供对应用层面操作(如启动Activity，发送broadcast，接受intent)的调用接口。
##总结 StackoverFlow.com上有人根据自己的理解总结了Context的用法，说得很有道理，以下是我的翻译。
正如Context的名字所说，它是一个应用/对象(applicaton/object)当前状态的上下文。它让新建的对象知道当前正在发生着什么。典型的用法，你可以调用它来得到关于你程序其它部分(Activity，package/application等)的信息。
你可以通过以下方式得到context: getApplicationContext(), getContext(), getBaseContext()或者this(当位于一个Activity class中时)。
典型用法：
新建对象：新建views, adapters, listeners等：
TextView tv = new TextView(getContext()); ListAdapter adapter = new SimpleCursorAdapter(getApplicationContext(), &amp;hellip;);</description></item><item><title>Sockets in Java -- Oracle Java Tutorial 翻译</title><link>https://blog.yuantops.com/tech/java-all-about-sockets-oracle-java-tutorial/</link><pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/java-all-about-sockets-oracle-java-tutorial/</guid><description>##课程：关于Sockets的一切 URL和URLConnection为获取因特网上的资源提供了一种相对高层次(high-level)的机制。但有时候，你的程序需要一种相对低层次(lower-level)的网络通信，譬如说，你可能需要编写一个客户端-服务器(client-server)程序。
在客户端-服务器程序中，服务器端提供一些服务：譬如处理数据库查询，或者发送当前的期货价格。客户端利用服务器提供的这些服务器，用来向用户显示数据库查询的结果，或者给投资者提供期货的购买建议。客户端和服务器端的通信因此必须是可信的。换言之，数据不能丢失，而且它到达客户端的顺序必须与服务器的发送顺序一致。
TCP协议提供了一个可信的、点到点的通信信道，因特网上的客户端-服务器端程序可以使用它来通信。为了基于TCP通信，客户端程序和服务器程序要和对方建立连接。每个程序各自将一个socket绑定到连接的一头。当通信时，客户端和服务器各自从与连接绑定的socket里面读/写数据。
##Socket是什么? 因特网上运行着的两个程序建立了一个双向的通信连接，Socket就是这个连接的一端。Socket类用来表示一个客户端程序和一个服务器程序间的连接。java.net包中提供了Socket和ServerSocket这两个类，它们分别是这一连接的客户端实现和服务器端实现。
##通过Socket读和写 Reading from and Writing to a Socket包含一个小例子，它演示了客户端程序如何从Socket读数据和向socket写数据。
##编写一对socket Client/Server Reading from and Writing to a Socket演示了客户端程序如何通过socket与一个存在的服务器端交互。Writing a Client/Server Pair则演示如何实现连接的另一端——服务器端的功能。
##原文链接 Lesson: All About Sockets</description></item><item><title>Socket是什么 -- Oracle Java Tutorial 翻译</title><link>https://blog.yuantops.com/tech/socket-definition-oracle-java-tutorial/</link><pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/socket-definition-oracle-java-tutorial/</guid><description>一般而言，一个服务器运行在一台电脑上，这个服务器有一个绑定了端口号的socket。这个服务器一边等待，一边守着socket监听从客户端发过来的连接请求。
在客户端：客户端知道服务器所在的主机的主机名(hostname)和服务器正在监听的端口号。为了发出连接请求，客户端尝试着连接服务器所在的主机名和端口。客户端同时也需要向服务器端证明自己的身份，因此它也绑定了一个本地的端口号以便在本次连接中使用。这一般是由系统指定的。
如果一切顺利，服务器会接受连接。一旦接受了连接，服务器会得到一个绑定了本地相同端口的新socket，这个socket的另一端被置为客户端的地址和端口。服务器需要一个新的socket,所以它能一边继续在原来的socket监听连接请求，一边处理已建立连接的客户端的需求。
在客户端，如果连接请求被接受，会成功新建一个socket。客户端能利用这个socket来与服务器端通信。
现在，客户端和服务器能通过向它们的sockets读/写数据来通信了。
定义
Socket是网络上运行着的两个程序所形成的双向通信连接的一端(endpoint)。每个socket都绑定了一个端口号，所以TCP层能确定数据接收方的程序。
连接的一端(endpoint)是一个IP地址和一个端口号的组合。每个TCP连接能被两个*连接的一端*唯一标志。这样，主机和服务器之间就能存在多个连接。
Java平台上的java.net包提供了Socket这个类，它实现了Java程序和网络上另一个程序的双向连接的一边。Socket类位于依赖于平台的实现方式的顶端，向Java程序隐藏了所有系统的细节。通过使用java.net.Socket类而不是系统的原生代码，Java程序能一种独立于平台的实现方式与网络通信。
另外，java.net包也包括了ServerSocket类，它实现的socket能被服务器用来监听、接受来自客户端的连接请求。
如果你想连接Web，那么URL类和与之相关的类(URLConnection, URLEncoder)可能比Socket类更适合。事实上，URL类是连接Web相对更高层次的方式，它也用到sockets作为底层的部分实现。
##原文链接 What Is a Socket?</description></item><item><title>[转载]Android Intent原理分析</title><link>https://blog.yuantops.com/tech/an-insight-of-android-intent/</link><pubDate>Sun, 11 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/an-insight-of-android-intent/</guid><description>##原文链接 Android Intent原理分析
##转载原文正文 Revision History
wylhistory
Abstract
Introduction
Intent的架构
Intent的发送过程
4.1 Intent消息在发送进程的逻辑
4.2 Intent发送在服务器端的执行
4.2.1 进入消息队列之前
4.2.2 进入消息队列后的处理
4.2.3 消息的分发过程
4.2.4 deliverToRegisteredReceiver的逻辑
4.2.5 processCurBroadcastLocked的逻辑
4.2.6 startProcessLocked的逻辑
Intent的接收过程
5.1 Receiver的注册
5.2 scheduleReceiver
5.3 scheduleRegisteredReceiver的逻辑
未分析
Abstract
主要是分析一下android的IPC通讯之Intent；
Introduction 任何一个操作系统，都有自己的IPC通讯机制，Android也不例外；
IPC通讯在linux下面通常包括共享内存，管道，消息队列等，这其中共享内存的效率比较高，我想；
这里将要说的Intent的通讯机制是基于Binder的，而Binder的机制本质上是共享内存；
Intent中文翻译为：n.意图，意向，目的 a.专心的；急切的；没有一个特别适合，所以我还是决定用英文；
它的作用，我想就是传达一些信息各特定的对象，或者广播一些信息各某些对象；这里涉及两方面的内容：
A） 消息的发送；
B） 消息的接收；
后面就会具体的展开；
讨论之前先看一个简单的例子： Intent intent = new Intent(AudioManager.ACTION_AUDIO_BECOMING_NOISY);
mContext.sendBroadcast(intent);
这是摘自HeadsetObserver.java的代码；
后面将会以此为例，分析发送和接收的过程；
Intent的架构 Intent的架构包括三方面：</description></item><item><title>HTTP Methods: GET vs. POST</title><link>https://blog.yuantops.com/tech/difference-between-http-get-and-post/</link><pubDate>Fri, 09 Jan 2015 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/difference-between-http-get-and-post/</guid><description>##HTTP是什么？
超文本传输协议(The Hypertext Transfer Protocol, HTTP)是为客户端(client)与服务器(server)之间的通信(communication)设计的。
HTTP是在客户端与服务器之间以请求-响应(request-response)方式工作的协议。
客户端可以是一个网页浏览器，服务器可以是一台提供web服务的主机上的某个应用程序。
例如：一个客户端(浏览器)向服务器提交了HTTP请求；服务器接着向客户端返回响应。响应中包含了请求的状态信息，同时可能包含所请求的资源。
##最常用的两种HTTP请求方式：GET和POST - GET: 向某个指定的资源申请数据
- POST: 向某个指定的资源提交需要处理的数据
##GET方式 注意，GET请求的查询字符串(name/value对)是包含在URL中发送的
/test/demo_form.asp?name1=value1&amp;amp;name2=value2
关于GET还需注意：
GET请求能被缓存
GET请求保存在浏览器的历史记录中
GET请求能被当作书签添加 GET请求永远不应用在处理敏感数据的场合
GET请求有长度限制
GET请求只应该用来获取数据
##POST方式 注意，POST请求的查询字符串(name/value对)是包含在HTTP消息体中发送的
POST /test/demo_form.asp HTTP/1.1 Host: w3schools.com name1=value1&amp;amp;name2=value2
关于POST还需注意：
POST请求不能被缓存
POST请求不保存在浏览器的历史记录中
POST请求不能被添作标签
POST请求没有长度限制
##GET与POST对比
GET POST 返回/刷新按钮 无影响 数据会被再次提交(浏览器应该会警示用户这一点) 书签 能被添作书签 不能被添作书签 缓存 能被缓存 不能缓存 编码方式 application/x-www-form-urlencoded application/x-www-form-urlencoded或者multipart/form-data。 历史记录 参数保存在浏览器记录中 参数不保存 数据长度限制 在传输数据时，GET方式会将数据添加到URL中，而URL的最大长度是2048个字符。 无限制 数据类型限制 只允许ASCII字符 无限制。二进制数据也是合法的。 安全 与POST相比，更不安全，因为GET方式数据是URL的一部分。永远不要用GET来发送密码之类的敏感信息！ 相对GET更安全一点，因为数据不会存储在浏览器历史记录或者服务器日志中。 可见性 每个人都能看见URL中的数据 数据不在URL中显示 ##原文链接 HTTP Methods: GET vs.</description></item><item><title>Buffered Streams -- Oracle Java Tutorial 翻译</title><link>https://blog.yuantops.com/tech/oracle-java-tutorial-buffered-stream/</link><pubDate>Wed, 31 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/oracle-java-tutorial-buffered-stream/</guid><description>Buffered Streams 缓冲流 此前我们所见识的例子使用的大多*非缓冲I/O*。非缓冲，意味着每一次读/写的请求都由底层的OS直接处理。这降低了程序效率，因为每一次请求往往会触发磁盘操作、网络活动、或者其它代价昂贵的操作。
为了减少这类消耗，Java平台实现了*缓冲I/O*流。输入缓冲流从一块别名为&amp;rdquo;缓存&amp;rdquo;(buffer)的内存区域中读入数据;只有当缓存区变空的时候，原生的输入API才会被调用。类似地，缓冲的输出流向一块缓存中写数据，只有当缓存区满了的时候，原生的API的输出API才会被调用。
程序能把一个非缓冲流转化为缓冲流。我们已经使用过几次这样的&amp;rdquo;包装类&amp;rdquo;了：非缓冲流作为参数传入缓冲流类的构造函数。下面就是一个例子，你可以在用它替代CopyCharacters代码中的构造函数以使用缓冲I/O：
inputStream = new BufferedReader(new FileReader(&amp;#34;xanadu.txt&amp;#34;)); outputStream = new BufferedWriter(new FileWriter(&amp;#34;characteroutput.txt&amp;#34;));
可以用来包裹非缓冲流的缓冲流类有4类：BufferedInputStream和BufferedOutputStream生成缓冲字节流, BufferedReader 和BufferedWriter 生成缓冲字符流。
洗刷(flush)缓冲流 在某些重要的时刻，我们等不及缓存填满就要将它的内容输出。这样的操作一般被称作*洗刷(flush)*缓存。
一些缓冲输出流支持&amp;rdquo;自动洗刷(autoflush)&amp;ldquo;，只要你在它的构造函数中指定某个参数即可。当开启了自动洗刷后，某些关键事件会触发洗刷。例如，一个自动洗刷的PrintWriter对象，每当*println*或者*format*被调用时都会自动洗刷缓存。
可以使用*flush*函数来手动洗刷缓存。可以对任何一个输出流使用*flush*函数，但只有在这个流被缓冲时才有效果。
注：flush也可以翻译成“刷新”，但我觉得这样可能造成含混，所以还是将它翻作“洗刷”来得直白。
原文链接 Buffered Streams</description></item><item><title>在GitHub pages中添加标签Tags(非插件方式)</title><link>https://blog.yuantops.com/tech/add-tags-in-gh-pages/</link><pubDate>Wed, 31 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/add-tags-in-gh-pages/</guid><description>参考内容 本文参考了以下内容：
Alphabetizing Jekyll Page Tags In Pure Liquid (Without Plugins)
Tips For Sorting Tags In GitHub Page With Jekyll
HOW TO USE TAGS AND CATEGORIES ON GITHUB PAGES WITHOUT PLUGINS
思路 Jekyll引擎按照post/page文件-layout模板-HTML文件的逻辑处理、生成数据，因此添加Tags功能时也应遵循对应的顺序。
1. 在_posts目录下新建post文件时，在yaml头中加入tags变量。如果有多个tag，那么用中括号括起来、逗号分开。
2. 在_layouts目录下，post文件引用的模板文件中，加入解析单个post文件的tags的逻辑，并显示。
3. 在博客文件夹的根目录下新建一个tags.html文件，列出博客所有文章的tags，通过Html定位符确定每个tag的位置。将这个页面的链接摆放在首页或者其它合适的地方。
步骤 Step 1 在_layouts目录下的post.html文件中，在你想Tags出现的地方加入下面的代码：
&amp;lt;p class=&amp;#34;entry-tags&amp;#34;&amp;gt; {% for tag in page.tags %}&amp;lt;a href=&amp;#34;{{ site.url }}/tags.html#{{ tag | cgi_ e scape }}&amp;#34; title=&amp;#34;Pages tagged {{ tag }}&amp;#34; rel=&amp;#34;tag&amp;#34; class=&amp;#34;post-tag&amp;#34;&amp;gt;{{ tag }}&amp;lt;/a&amp;gt;{% unless forloop.</description></item><item><title>Jekyll安装指南</title><link>https://blog.yuantops.com/tech/jekyll-installation/</link><pubDate>Tue, 30 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/jekyll-installation/</guid><description>环境准备 准备安装Jekyll前，确保系统满足以下条件：
Ruby
RubyGems
Linux, Unix, 或者 Mac OS X
Nodejs, 或者其它JavaScript运行环境
以Ubuntu为例，安装上述软件的方法：
Ruby
$ sudo apt-get install ruby, ruby-dev 要注意，*ruby-dev*包需要一并安装，否则在后续会报错。
在Redhat/Fedora下，需要安装的软件包为ruby,ruby-devel。有可能还需要安装gcc包。
$ sudo yum install ruby, ruby-devel, gcc
RubyGems
RubyGems是Ruby程序包管理器，类似Redhat的RPM。更多的概念介绍，请参看整理Ruby相关的各种概念。
新版本的Ruby已经包含RubyGems，无需额外安装了。
Nodejs
$ sudo apt-get install nodejs
设置Gemfile 将GitHub上你的博客Repo克隆到本地。假设Repo的根目录为blog。终端路径切换到blog目录，新建名为Gemfile的文件，并填充内容:
source &amp;#39;https://rubygems.org&amp;#39; gem &amp;#39;github-pages&amp;#39; 使用RubyGems安装Jekyll 终端路径切换到blog，运行命令： $ sudo gem install jekyll
运行Jekyll，查看博客效果 终端路径切换到blog，运行命令： $ jekyll serve</description></item><item><title>Byte Streams -- Oracle Java Tutorial 翻译</title><link>https://blog.yuantops.com/tech/oracle-java-tutorial-byte-stream/</link><pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/oracle-java-tutorial-byte-stream/</guid><description>Byte Streams 字节流 程序使用*字节流*来处理8bit字节的输入和输出。所有的字节流类都派生(descend)自InputStream和OutputStream。
字节流类有很多。为了演示字节流的工作原理，我们将关注文件的I/O字节流,FileInputStream和FileOutputStream。其它字节流类的使用方法往往与之类似，仅在构造的方法上存在差别。
使用字节流 下面我们通过一段代码CopyBytes来演示FileInputStream和FileOutputStream的用法。这段代码通过字节流逐字节地拷贝xanadu.txt。
import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class CopyBytes { public static void main(String[] args) throws IOException { FileInputStream in = null; FileOutputStream out = null; try { in = new FileInputStream(&amp;#34;xanadu.txt&amp;#34;); out = new FileOutputStream(&amp;#34;outagain.txt&amp;#34;); int c; while ((c = in.read()) != -1) { out.write(c); } } finally { if (in != null) { in.close(); } if (out != null) { out.</description></item><item><title>Character Streams -- Oracle Java Tutorial 翻译</title><link>https://blog.yuantops.com/tech/oracle-java-tutorial-character-stream/</link><pubDate>Mon, 29 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/oracle-java-tutorial-character-stream/</guid><description>Character Streams 字符流 Java平台使用Unicode字符集存储字符值(character value)。字符流I/O自动将内部的Unicode格式翻译成本地的字符集，反之亦然。在西方的使用环境(locale)下，本地字符集往往是8bit的ASCII码的超集(superset)。
对大多数程序来说，使用字符流的I/O不会比使用字节流的I/O更复杂。与输入和输出相关的流类会自动完成与本地字符集的翻译过程。一个使用字符流而不是字节流的程序，它会自动使用本地字符集，而且它可以完成国际化的过程——不需要程序员付出过多的额外工作。
如果国际化的需求优先级不高，你尽管以最简单的方式使用字符流类，而不需太关注字符集的问题。如果之后有了国际化的需求，你的程序也可以轻松地予以修改。参见国际化的章节了解更多。
使用字符流 所有的字符流类都派生自Reader和Writer。与字节流一样，有专为文件I/O而设的字符流类：FileReader和FileWriter。下面的CopyCharacters代码演示了它们的使用方法。
import java.io.FileReader; import java.io.FileWriter; import java.io.IOException; public class CopyCharacters { public static void main(String[] args) throws IOException { FileReader inputStream = null; FileWriter outputStream = null; try { inputStream = new FileReader(&amp;#34;xanadu.txt&amp;#34;); outputStream = new FileWriter(&amp;#34;characteroutput.txt&amp;#34;); int c; while ((c = inputStream.read()) != -1) { outputStream.write(c); } } finally { if (inputStream != null) { inputStream.close(); } if (outputStream != null) { outputStream.</description></item><item><title>OSC Android源码学习笔记 四 listview初始化、获取数据、加载数据的流程</title><link>https://blog.yuantops.com/tech/osc-android-app-notes-4/</link><pubDate>Sat, 27 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/osc-android-app-notes-4/</guid><description>OSC App显示的信息分为资讯(news)，博客(blog)，问答(Question)，动弹(tweet)几屏，每屏对应一个ListView。以资讯(news)为例，粗略看一下它的ListView是如何初始化、获取数据、加载数据的。
实例化一个ListViewNewsApapter并添加到lvNews：
lvNewsAdapter = new ListViewNewsAdapter(this, lvNewsData, R.layout.news_listitem); ListViewNewsApapter这个类继承BaseAdapter，重写了getView()方法。值得注意的是，getView()方法中news实体被被作为Tag添加到了listView的ItemView中。
为lvNews设置lvNewsAdapter。lvNews和lvNewsAdapter都是Main这个类持有的变量，而不是某个函数的局部变量。
为lvNews设置OnClickListener，这个Listener以匿名内部类方式初始化： 当点击单个item view时，从view中取出news这个Tag，然后使用UIHelper.showNewsRedirect()方法跳转到新闻阅读详情页。
实例化一个lvNewsHandler：
lvNewsHandler = this.getLvHandler(lvNews, lvNewsAdapter, lvNews_foot_more, lvNews_foot_progress, AppContext.PAGE_SIZE);
这个Handler定义了当接收到有数据更新的通知时，应该作何处理。主要是通知adapter数据发生了变化：
adapter.notifyDataSetChanged();
下载数据，加载数据：
loadLvNewsData(curNewsCatalog, 0, lvNewsHandler, UIHelper.LISTVIEW_ACTION_INIT); 新开进程，调用appContext.getNewList()从服务器获取数据。数据获取完成后，通过传入的lvNewsHandler发送Message，回调handleMessage(Message msg)方法。</description></item><item><title>开源中国安卓客户端源码学习笔记 三 自定义Exception类</title><link>https://blog.yuantops.com/tech/osc-android-app-notes-3/</link><pubDate>Thu, 25 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/osc-android-app-notes-3/</guid><description>net.oschina.app包中包含四个类的定义文件，它们分别是AppConfig, AppException, AppManager, AppStart。其中AppStart类继承Activity，是跳转界面。AppException类是Exception的子类，是自定义的异常类。
AppException类中有8个final static类型的类变量，定义异常类型: network, socket, http, xml, io, run, jason几种。这个类中有对应的静态方法，以Exception为形参，返回对应的新建对象。值得注意的是，代码中预留了debug的选项，如果在新建AppException对象时传入“debug”参数，那么对应的Exception信息会被写到文件中保存。
这个类中定义了异常的处理方式：收集错误信息，然后显示异常信息&amp;amp;发送错误报告。显示异常信息和发送错误报告的过程在新建的Thread里完成。</description></item><item><title>使用OpenSSL工具制作证书的方法</title><link>https://blog.yuantops.com/tech/ssl-creation-guide/</link><pubDate>Wed, 24 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ssl-creation-guide/</guid><description>之前一篇文章介绍了SSL证书的一些细节，这篇文章介绍OpenSSL工具的基本使用方法。老实说，OpenSSL工具实在是太难用了，我参考了How To Setup a CA和基于 OpenSSL 的 CA 建立及证书签发这两篇文章，捣鼓了很久才理清流程。虽然原理很清楚，但是操作起来却不那么容易，这告诉我们要多实践才对，不然发现不了问题。
一些坑 在使用openssl ca命令时，如果不手动指定-config参数，它会自动调用/etc/pki/tls/openssl.cnf作为-config配置文件，这个openssl.cnf文件里定义了要调用的CA证书、私钥路径。如果我们在创建CA时将它的证书和私钥等文件保存在了别处，或者/etc/pki/tls/openssl.cnf里的定义的那些文件不存在，那么在openssl ca找不到要使用的这些文件时，就会报错。其中典型的错误有：
Using configuration from /etc/pki/tls/openssl.cnf unable to load CA private key 139911890630472:error:0906D06C:PEM routines:PEM_read_bio:no start line:pem_lib.c:703:Expecting: ANY PRIVATE KEY 所以，我们如果想自定义CA的目录位置，那么要事先1）按照OpenSSL的默认配置建立相应的目录结构，2）定制openssl.cnf文件，修改CA目录的路径定义。
建立CA，生成Root证书 生成CA目录结构 假设我要将/root/newCA作为CA文件根目录，那么在Terminal中敲入命令：
[root@node ~]# pwd /root [root@node ~]# mkdir -p ./newCA/{private,newcerts} [root@node ~]# touch ./newCA/index.txt [root@node ~]# echo 01 &amp;gt; ./newCA/serial
定制openssl.cnf文件 将/etc/pki/tls/openssl.cnf文件复制到newCA目录下，将CA_default下面的dir的值更新为自定义的openssl.cnf文件的路径(在本文中为/root/newCA)。
除此之外，出于方便后续设置的目的，还可以修改openssl.cnf文件中[req_distinguished_name]区域内后缀为default的变量，将它们预设合适的值。下面是我修改后的样子：
&amp;gt; [ req_distinguished_name ] countryName = Country Name (2 letter code) countryName_default = CN countryName_min = 2 countryName_max = 2</description></item><item><title>BIND安装笔记</title><link>https://blog.yuantops.com/tech/bind-installation-guide/</link><pubDate>Tue, 23 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/bind-installation-guide/</guid><description>安装环境 网络环境：两台KVM虚拟机，通过NAT方式组成子网(IP地址分别为192.168.100.139, 192.168.100.172)，彼此能ping通，均能访问互联网
系统：Redhat 6.6
要解析的域名：yuantops.com 安装BIND软件包 $ yum install bind bind-utils
为要解析的域名生成DNSSEC KEY 这一步不是配置基本DNS解析器时必须包括的步骤，因此可以省略。
DNSSEC是为了解决DNS欺骗和缓存污染而设计的一种安全机制。由于DNS域名解析系统在设计之初没有考虑到安全问题，经常有针对DNS系统的攻击发生，而且由于DNS协议十分脆弱，攻击一旦发生就会造成大面积的影响甚至瘫痪。DNSSEC的原理是通过引入加密技术，依靠数字签名保证DNS应答报文的真实性和完整性。具体的介绍请见DNSSEC的原理、配置与部署简介一文。
假设我要解析的域名为yuantops.com，准备将这个域名对应的DNSSEC KEY文件保存在/var/named/路径下。
&amp;gt; $ cd /var/named
&amp;gt; $ dnssec-keygen -a HMAC-SHA256 -b 256 -n USER -r /dev/urandom yuantops.com
在/var/named/路径下生成了文件名形如Kyuantops.com.+163+15844.key和Kyuantops.com.+163+15844.private的一对key文件。
启用rndc工具作为BIND的控制工具 这一步同样不是配置一个最基本的DNS解析服务器所必须包含的步骤，因此可以省略。
rndc是BIND安装包提供的一种域名服务控制工具，它可以运行在其他计算机上，通过网络与DNS服务器进行连接，然后根据管理员的指令对named服务进行远程控制，此时，管理员不需要DNS服务器的根用户权限。更重要一点，rndc能实现数据的热更新，这对繁忙的实际场景而言是十分有必要的。具体的介绍可以请见这篇文章。
使用rndc-confgen命令生成rndc的配置文件。
&amp;gt; $ rndc-confgen -a -r /dev/urandom
在/etc路径下生成了rndc.key文件。
配置BIND对域名的解析 这一步是必须完成的、最重要的步骤。
新建yuantops.com域的zone文件，保存到/var/named/dynamic目录。
域的zone文件有自己的语法规范，配置起来需要事先对DNS的术语有一定了解。可以参看文章一和 文章二。
下面是域yuantops.com的zone文件yuantops.com.db的内容:
&amp;gt;$TTL 86400 ; 24 hours could have been written as 24h or 1d</description></item><item><title>开源中国安卓客户端源码学习笔记 二 欢迎界面跳转与渐变效果</title><link>https://blog.yuantops.com/tech/osc-android-app-notes-2/</link><pubDate>Tue, 23 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/osc-android-app-notes-2/</guid><description>OSC客户端启动时会先显示欢迎界面，再跳转到主页，其中跳转过程有渐变效果。
这里使用了AlphaAnimation类。AlphaAnimation类能实现渐进渐出的效果，官方文档里说“This animation ends up changing the alpha property of a Transformation”。alpha property可以理解为透明度，&amp;rdquo;0.0&amp;rdquo;为全透明，“0.5”为半透明，“1.0”时不透明。
//渐变展示启动屏 AlphaAnimation aa = new AlphaAnimation(0.3f,1.0f); aa.setDuration(3000); view.startAnimation(aa); aa.setAnimationListener(new AnimationListener() { @Override public void onAnimationEnd(Animation arg0) { redirectTo(); } @Override public void onAnimationRepeat(Animation animation) {} @Override public void onAnimationStart(Animation animation) {} }); 另外，欢迎界面的图片可以更新。从代码分析，在将View设置为ContentView之前，程序会检查欢迎界面对应缓存文件夹里的图片文件，图片文件的文件名有一个时间期限，如果今天正好落在这个期限内，那么就将它设为背景图片。如此可以推测APP会在启动后自动下载新的图片文件(如果存在的话)到缓存文件夹，从而达到更新效果。
果然，在跳转到Main Activity后，在onCreate()方法里调用了checkBackGround()方法。这个方法会新开一个Thread去服务器检查是否有新的图片需要下载，如果有，那么会下载下来。</description></item><item><title>开源中国安卓客户端源码学习笔记 一</title><link>https://blog.yuantops.com/tech/osc-android-app-notes-1/</link><pubDate>Mon, 22 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/osc-android-app-notes-1/</guid><description>##前言 开源中国(OSCHINA)是国内一个开源社区,社区自己开发了Android和iOS平台的客户端，而且将各自的代码开源了。值得夸奖的是，他们的Android APP不是基于HTML，而是Android原生API。我最近在学习它Android App的源代码，毕竟像它这样性能优秀、注释齐全的开源项目是比较稀少的。
希望能通过阅读源代码，学到一些Android开发的实战技巧，并加深对已有知识的理解。
##学习笔记一 利用getApplication()共享全局数据
程序启动Activity是net.oschina.app.AppStart。这个Activity类持有一个自定义的AppContext成员。查看net.oschina.app.AppContext类的定义，作者说它是“全局应用程序类，用于保存和调用全局应用配置及访问网络数据”。
AppContext类是Application类的子类。Google了getApplication()函数，找到了一篇介绍得比较明白的文章：
- android利用getApplication()共享全局数据
在平时开发中，如果需要一些能被所有Activity和View访问到的全局数据，就可以自定义一个继承Application类的子类，扩展它所持有的成员。值得注意，还需在android Manifest.xml文件中将application的android:name属性指定为自定义的类。
另外,关于getApplication()和getApplicationContext()的区别,stackoverflow上有人这么解释:
虽然当前Anroid Activity和Service的实现方式使得getApplication()和getApplicationContext()返回相同的object，但不能保证它们将来会一直这样。 如果你想在Manifest.xml文件中注册Application class，那么**永远不要**调用getApplicationContext()并将其cast为你的application类，因为它返回的很可能不是你的application实例。 getApplication()仅仅在Activity和Service类中可以被调用，而getApplicationContext()则是在Context类中被声明的。这意味着，譬如说你写了一个Broadcast Receiver，Broadcast Receiver本身不是一个Context类，尽管它能通过onReceive()方式获得一个Context类的引用，这时你就只能调用getApplicationContext()了——这也就意味着，不能确保在BroadcastReceiver中访问到application。 另外，Android的官方文档中提到，你**不应该**需要去继承Application类: There is normally no need to subclass Application. In most situation, static singletons can provide the same functionality in a more modular way. If your singleton needs a global context (for example to register broadcast receivers), the function to retrieve it can be given a Context which internally uses Context.</description></item><item><title>制作属于自己的字母favicon</title><link>https://blog.yuantops.com/tech/make-custom-character-favicon/</link><pubDate>Sat, 20 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/make-custom-character-favicon/</guid><description>每个自己搭建博客的人，应该都想自己的博客更具个性。favicon是浏览器浏览网页时标签左边的那个小图标，是可以自己设计的。
这里，推荐一个网站：faviconist.com。你可以输入一个字母，得到这个字母的图标，而且字体、文字前景色、背景色都可以调整。调整到满意后，下载到本地，保存到对应的网页文件夹，就可以了。
效果可以参见我的网页。</description></item><item><title>Java 的一些术语解释</title><link>https://blog.yuantops.com/tech/java-terminology-explanation/</link><pubDate>Sun, 14 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/java-terminology-explanation/</guid><description>作为JAVA初学者，往往弄不清楚一系列术语的概念。这篇文章搬运文章一与文章二，解释JRE与JDK, JavaSE、JavaME与JavaEE，Java版本等术语 。
JRE vs JDK JRE: Java Runtime Environment
基本说来它是Java Virtual Machine，你的Java程序在它上面运行。它也为浏览器提供Applet运行插件。
JDK: Java Development Kit
Java软件开发包，它不仅包括 JRE,还包括编译器等其它工具(JavaDoc, Java Debugger等)。它用来创建、编译程序。
一般说来，如果你仅仅想让Java程序在自己的电脑和浏览器上跑起来，那么只需安装JRE。如果你想用Java编程，那么需要安装JDK。
JavaSE，JavaME和JavaEE 因为围绕Java形成的生态圈十分庞大，所以Sun公司提供了Java的不同发行版。
JavaSE: Java Standard Edition
适合于客户端软件、常规程序等。我们平时所使用的、所下载的Java版本一般都是它。
JavaME: Java Mobile Edition
通常是老式手机游戏所产生的平台，它对Java进行了精简，使其更适合低性能的处理器。
JavaEE: Java Enterprise Edition
通常用来研发服务器端的产品，因此往往它包含很多服务器需要用到的包。
Java的版本号 我们在下载安装Java JRE或者JDK后，使用&amp;rdquo;java -version&amp;rdquo;命令查看当前的Java版本，会发现类似下面的信息：
java version &amp;#34;1.7.0_71&amp;#34; Java 1.7是我机器上的java版本号，它也被称为Java 7：它们是一个东西，两个名称。再累赘一点地说，它也是JavaSE 7。
扩展阅读 更详细、更权威的资料，可以阅读Oracle的Java SE Technologies文档。</description></item><item><title>SSL术语与基本原理</title><link>https://blog.yuantops.com/tech/ssl-terminologies-and-concepts/</link><pubDate>Sat, 06 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ssl-terminologies-and-concepts/</guid><description>非对称加密的又一大应用是SSL。对于SSL的介绍，阮一峰有一篇深入浅出的博客，推荐阅读：数字签名是什么？。这篇文章也非常不错：SSL/TLS Strong Ebcryption: An introduction。
SSL协议对互联网的安全十分重要。要理解SSL协议，必须先理解几个基本概念：信息摘要(message digest)，数字签名(digital signature)，数字证书(digital certificate)。阮一峰的博客里写得十分清楚了，看完后做一点自己的笔记。
SSL术语 公钥(public key): 非对称加密密钥对中可以分发给其它人的一方。
私钥(private key): 非对称加密密钥对中自己保存的一方。
信息摘要(message digest): 对一段很长的数据消息，计算它的Hash函数值，得到的一串*较短*且*定长*的短数值。Hash函数可以是MD5或者SHA 1。Hash函数过程是单向不可逆的，不可能通过message digest 反推出原数据信息。同时，message digest也是独一无二的。可以理解为某一段数据内容独一无二的特征值。
数字签名(digital signature): 使用用户私钥对信息摘要(message digest)进行加密，生成的信息。数字签名只能用用户的公钥解开。反过来，如果用户Alice的公钥成功解密了数字签名，那么一定能确定这个签名的签发者是用户Alice(因为只可能是Alice的私钥签发了它)。
数字证书(digital certificate): 由某个被信任的机构(如Certificate Authority，CA)签发、认证用户身份的数字文件。(数字证书的内容复杂，将在另外一篇博客中专门介绍)。
SSL基本原理 这里介绍的是SSL的设计思想和大致原理，不是实现细节。转述自从阮一峰的博客。
假设用户Alice有属于自己的公钥/私钥对。她准备和好朋友Bob，Susan等通信。
Alice把自己的公钥送给朋友们：Bob，Susan每人一把。
Bob如果要给Alice写一封保密的信，那么他写完后用Alice的公钥加密，就可以达到保密的效果。
Alice收到信后，用自己私钥解密，就看到了信件内容。这里要强调的是，只要Alice的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。
试思考：如果Alice事先没有把自己公钥送给自己的朋友们，她自己手中也没有朋友们的公钥，那他们之间通信如何保证不被篡改？
假设Alice要给Bob写信。她写好信(message)后，先使用Hash函数生成信息摘要(message digest)。然后，她使用私钥，对这个摘要加密，生成数字签名(digital signature)。最后，她把自己的信件内容、数字签名，还有自己的公钥一起发送给Bob。
Bob收到了信件。他取出Alice的公钥、数字签名，用公钥解密数字签名，得到信息摘要;他再读出信件内容，用Hash函数自己计算内容的信息摘要。如果取出来的摘要和算出来的摘要吻合，那么这封信就未被修改过。
可是，万一黑客John截获了Alice发给Bob的信件，然后自己编造了一些内容，生成摘要、用自己密钥加密生成数字签名，再连同自己的公钥一起发给Bob，他就可以冒充Alice了。Bob如何确定取出的公钥就是Alice的，而不是别人(例如，黑客John)的？
Bob无法确定公钥是不是属于Alice，于是想到一个办法：他建议Alice去找权威机构(例如，certificate authority，简称CA)给她的公钥做认证，做个证书(certificate)。Alice领取了一份申请表格，填入自己的姓名、住址、联系方式、和自己的公钥，跑到CA去提交。CA接受申请，确认是Alice本人无误，就用自己的私钥处理Alice的表格内容，生成数字签名并附在申请表格后面，这就成了“数字证书”(digital ceritificate)。
以后Alice给Bob写信，就会发送信件内容+数字签名+数字证书三部分。Bob收到来信，先检查数字证书的真伪。如果为真，那么从数字证书中取出Alice的公钥。这时可以确认得到的是Alice的真实公钥。
数字证书的现实应用：https中的SSL协议 首先，客户端向服务器发出加密请求。</description></item><item><title>SSL证书的细节与制作方法</title><link>https://blog.yuantops.com/tech/ssl-certificate-details-and-creation-guide/</link><pubDate>Sat, 06 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ssl-certificate-details-and-creation-guide/</guid><description>在上篇文章中，讨论了数字证书(digital certificate)的重要意义。在实际中，Internt工程任务组(IETF)PKI X.509专门负责制定数字证书的格式，并提出了一套标准。根据这套标准(X.509)，互联网上的各级单位各自予以实现，从而形成一套完备的公钥基础设施(Public Key Infrastructure, PKI)。这是本篇文章将要讨论的内容。
SSL证书的X.509标准 X.509 规定一份digital certificate应该由这几部分构成：
Certificate Data
Version (marked as X.509 v3, even if v4 or v5)
Serial number
Signature algorithm ID
Issuer name(DN, Distinguished Name)
Validity (start and end time)
Subject name(DN)
Subject Public key Extensions (added in X.509 v3): Extra identification information, usage constraints, policies, and general kitchen-sink area
Certificate Signature Algorithm</description></item><item><title>SSH登录原理</title><link>https://blog.yuantops.com/tech/ssh-login-procedure/</link><pubDate>Fri, 05 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ssh-login-procedure/</guid><description>关于SSH登录的原理，阮一峰的这篇博客写得很清楚，值得一看。
&amp;gt;SSH原理与运用(一)
读完这篇博客后，下面是笔记和摘抄。
SSH密码登录的流程 远程主机收到用户的登录请求，把自己的公钥发给用户。
用户使用这个公钥，将登录密码加密后，发送回来
远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。
如何防范&amp;rdquo;中间人&amp;rdquo;攻击 如果有人拦截了远程主机发给用户的公钥，然后将自己的公钥发送给用户，可能会造成远程主机密码泄漏(著名的“中间人攻击”)。用户要识别公钥的真伪，没有更好的办法，只有比较收到的公钥的fingerprint（公钥的MD5值）是不是与服务器公布在网站上的fingerprint相同。
在用户初次SSH登录一台远程主机时，终端往往会显示远程主机的fingerprint和一条Warning，询问是否确定远程主机的身份并继续。当用户选择确认后，远程主机的公钥会记录到本地系统的known_hosts文件中。下次再登录时，系统如果发现远程主机的公钥记录在案，就不再发出Warning。
SSH公钥登录的流程 以密码方式SSH登录远程主机，每次都需要输入密码，这样既麻烦，又存在密码泄露的潜在危险。公钥登录可以解决这两个问题。(有的高安全规格的服务器甚至不允许用户以SSH密码登录，只允许以SSH公钥方式登录。)
公钥登录的流程：
1. 用户将自己的公钥存储在远程主机上。
2. 登录时，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。
3. 远程主机用实现存储的公钥解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。
Linux下生成公钥/私钥对的命令 在用SSH公钥登录时，第一步需要用户提供自己的公钥。Linux，特别是服务器环境下，经常会有用到公钥/私钥对的场景，生成它们的命令也十分基础。
生成公钥/私钥对
&amp;gt;$ ssh-key
运行命令，并确认它的默认设置，会在$HOME/.ssh/目录下生成两个文件： id_rsa.pub和id_rsa。rsa意味着它们是以RSA加密算法生成的。以pub为后缀的是公钥，可以分发出去(会在下一步添加到远程服务器)；后者是自己的私钥，要妥善保存。
存储用户公钥到远程服务器
用户公钥需要添加到远程主机上对应用户的$HOME/.ssh/authorized_keys文件中，以字符串形式附到末尾。有两种方式可以做到：
ssh系列命令 &amp;gt; $ ssh-copy-id user@host
等价的手工操作
&amp;gt; $ ssh user@host #登录远程主机
&amp;gt; $ mkdir -p $HOME/.ssh #如果用户主目录下.ssh目录不存在则创建
&amp;gt; $ gedit .ssh/authorized_keys #用文本编辑器打开.ssh/authorized_keys文件，将上一步生成的id_rsa.pub文件里的内容附在末尾。
个人思考：信任的锚点如何建立 SSH无论密码登录还是公钥登录，为了保证传输的安全，不得不考虑各种潜在的安全漏洞。由于SSH引入了公钥/私钥机制，可以认为已经建立的连接是安全的。最高危的时刻是建立连接的时候：谁来确认对方的身份、建立对它的信任？
机器是不能帮我们做到的。所以在首次登录远程主机时，终端会显示远程主机公钥的fingerprint，并询问是否要继续连接它。这时，就需要我们自行承担风险：我信任，或者不信任。一旦选择&amp;rdquo;信任&amp;rdquo;，就意味着建立了&amp;rdquo;信任的锚点&amp;rdquo;。后面的连接都会根据这个锚点而建立信任关系。
SSH公钥登录的方式也是同理。对一台远程主机而言，当用户的公钥被附到authorized_key文件末尾时，就意味着建立了&amp;rdquo;信任的锚点&amp;rdquo;。执行这个操作的人，就是建立&amp;rdquo;信任的锚点&amp;rdquo;的人，显然也是承担风险的人。</description></item><item><title>关于Git,需要理解的几个关键概念</title><link>https://blog.yuantops.com/tech/key-concepts-to-understand-git/</link><pubDate>Fri, 05 Dec 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/key-concepts-to-understand-git/</guid><description>Git的控制哲学十分优雅,特别是了解它后会更为之倾倒。Git的入门在此不赘述。在掌握常用命令之后,再思考下面这些概念,相信对Git的认识会得到提升。
Git基于Commit,每个Commit有独一无二的SHA 1作为标志 Git有Working Tree,Index,Repo的概念。Working Tree指当前的工作目录,当这个目录下有改动时,通过add命令将改动添加到Index区域。当改动都被加到了Index、需要提交时,使用commit命令将它们提交到Repo中。这次提交会形成一个Commit记录,它相当于当前状态的一个SnapShot。
基于Commit的版本控制是十分优雅的想法。原因在于：
每次Commit,系统只是保存了文件的改变(而不是改变后的文件),这样节省了磁盘空间 每次Commit都是在上次Commit的基础上发生的(当Git Repo初始化时建立第一个Commit,它是所有Commit的最终基础),包含了对上次Commit的引用,因此一次次的Commit形成了一个链式结构 每个Commit都有唯一的标志符号: (一般为)SHA 1值。它是Commit的内容经过数学计算得到的。
通过引入Commit,我们的所有改动都被纳入系统中,使改动变得有迹可循。
Branch, HEAD, TAG本质上都是为Commit所取的别名 只有先理解“Git基于Commit”,才能理解上面这句话。
因为Repo的更改记录是以一个个Commit组织起来的,它们就像一个个节点,能确定某个确定时刻的目录状态。因此,当我们想要切换到某个状态时,就要在庞大的Commit网络中定位某个Commit,并转到那个Commit。但唯一标准Commit的SHA 1值是很长的一串数字,为了方便识别与输入,就给这些SHA 1添加字符串的别名。因此Branch,HEAD,TAG本质上都是SHA 1的别名,确定Commit用的。
但Branch, HEAD, TAG毕竟有特殊的地方(不然为什么不给所有的Commit都取别名呢？),它们标记的是特殊的Commit：
Branch标记某个分支上离现在时刻最近的那次Commit。显然,随着在分支上不断提交Commit,Branch的指向对象也不断前进。试想一棵有枝干和树叶的树,那么Branch就是所有树枝末端的那片叶子。又因为每个Commit都包含它父Commit的标识(SHA 1值),所以确定了一个分叉的末端,就相当于确定了这个分叉上的所有Commit。一般而言,Git Repo都默认存在一个叫master的Branch。
HEAD标记当前工作在哪个Commit位置。试想我正在开发软件项目,5个不同分支对应相对5个独立的功能,我要接着修改哪一个分支,就把HEAD移到这个分支上。又因为Branch指向分支的最新Commit,所以也就是把HEAD移到了这个Branch上。当然,如果我不想接着某个Branch的最新进度修改,当然也是可以的,直接切换到那个Commit即可。总之,可以将HEAD想象成*我此时此刻站着干活的地方*。
TAG是单纯的给Commit的SHA 1取的别名。
Checkout其实是在移动HEAD 只有理解了HEAD的意义,才能理解上面这句话。
当我们谈论“在不同branch之间切换时”,真正起作用的是HEAD。既然HEAD指向的是某个Commit,那么checkout的参数可以是任何能确定Commit的标志(Branch,TAG,或者直接某个SHA 1值)。当然,checkout命令的用法很多,也有特殊情况checkout命令不会改变HEAD指向的Commit。</description></item><item><title>SSL学习笔记 前言</title><link>https://blog.yuantops.com/tech/ssl-series-introduction/</link><pubDate>Sun, 30 Nov 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/ssl-series-introduction/</guid><description>最近实习时接触到了SSL协议，CA证书，ssh登录之类的东西，总是一知半解的感觉非常不好，于是我决定好好钻研一下。在网上查找了很多资料后，终于理清了很多以前很模糊的知识点。用几篇博客来记录一下，算是一个总结。
SSL(Secured Sockets Layer)与SSH(Secure Shell)，是用来解决网络传输中安全问题的协议。如何保证传输安全，使消息不被窃听、不被篡改，这需要用到加密技术。所以，要理解SSL中CA certificate的意义、ssh登录的工作原理，首先得理解它们所基于的加密原理: 非对称加密。
非对称加密技术是在信息论的理论基础上，以数学为工具的现代加密技术。它是现在最先进、最不易破解的加密技术。由于非对称加密技术在这一系列概念中的基础性地位，会有单独一篇文章介绍它的历史渊源和数学原理。
非对称加密技术与对称加密技术最明显的区别之处在于，它的密码都是以“公钥/密钥”形式成对存在的。如果要使用非对称加密技术，就出现了很自然的疑问：如何生成这些公钥/密钥对呢？我又该如何使用、部署它们？在Linux系统中，有一些非常强大、非常好用的命令工具帮助我们操作它们。这些命令会在后续谈论应用的技术实现的文章中介绍。(默认Linux环境)
非对称加密技术最著名的，也是本系列文章将会介绍的，是两大应用：SSH登录和SSL协议。SSH登录的原理相对简单，阮一峰的博客上有几篇文章介绍得非常详细好懂，因此只会有一篇文章讨论它。
而SSL协议，内容会多一些。首先，参考阮一峰的博客，会有一篇文章关于SSL加密的基本原理(包括Digest, Signature, Certificate等概念)。其次，因为Certificate在现实中使用得非常广泛，会有一到两篇文章介绍Certificate证书与X.509标准，也会介绍CA以及Certificate的&amp;rdquo;信任链&amp;rdquo;，PKI等概念。然后，会有一篇文章介绍如何为自己的域名生成Certificate。最后，从另外一个角度出发，会有一篇文章讨论当浏览器通过https链接访问网页时的交互流程(基本上翻译一篇国外的博客)。
非对称加密技术也可以在DNS系统中使用，即DNSSEC技术。关于这一技术，如果有时间的话，也会有一到两篇博客予以介绍。</description></item><item><title>vim增加markdown语法高亮支持</title><link>https://blog.yuantops.com/tech/vim-add-markdown-syntax-support/</link><pubDate>Sun, 30 Nov 2014 00:00:00 +0000</pubDate><author>yuan.tops@gmail.com (yuantops)</author><guid>https://blog.yuantops.com/tech/vim-add-markdown-syntax-support/</guid><description>markdown是一种非常简洁美观的语法格式，非常适合用来撰写博客(简书 语法简介)。在linux下，我个人最习惯用vim做文本编辑器。那么，如何使vim支持markdown的语法高亮呢？
vim是支持自定义语法高亮插件的。于是，问题就变成了两部分：
1. 找到markdown语法高亮显示的vim配置文件
2. 在vim中导入这个配置文件
vim配置文件下载
vim语法配置文件一般后缀为.vim。markdown的语法配置文件可以从下面链接中找到，假设它为markdown.vim, 将其下载到本地。
vim官网链接, 或者这个项目的最新github项目
配置文件导入
vim自定义配置文件的导入和安装见链接。 在这里我将其转述如下：
在.vimrc文件(.vimrc文件一般在$HOME目录下，若不存在则新建)中添加一条语句，定义一种语法格式，以及这种格式对应的配置文件。
以本文为例，假设markdown.vim保存路径为$HOME/.vim/markdown.vim，则在.vimrc文件中添加
&amp;gt; au! Syntax markdown source $HOME/.vim/markdown.vim
注: 配置文件路径一定要正确配置
再在.vimrc文件中添加一条语句，规定何种后缀名的文件适用这种语法格式。
以本文为例，我想后缀名为md与markdown的文件以markdown格式显示，那么在.vimrc中添加语句
&amp;gt; au BufRead,BufNewFile *.md set filetype=markdown
&amp;gt; au BufRead,BufNewFile *.markdown set filetype=markdown
保存.vimrc文件并退出，整个配置过程结束。</description></item></channel></rss>